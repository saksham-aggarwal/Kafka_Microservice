[2019-08-14 08:01:53,069] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-08-14 08:01:53,073] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 08:01:53,073] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 08:01:53,074] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 08:01:53,074] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-08-14 08:01:53,091] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-08-14 08:01:53,092] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-08-14 08:01:53,102] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,102] INFO Server environment:host.name=SAKSHAMA2012.pacific.costcotravel.com (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,102] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,102] INFO Server environment:java.vendor=AdoptOpenJDK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,103] INFO Server environment:java.home=D:\java\jdk (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,105] INFO Server environment:java.class.path=..;D:\kafka_2.12-2.3.0\libs\activation-1.1.1.jar;D:\kafka_2.12-2.3.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\argparse4j-0.7.0.jar;D:\kafka_2.12-2.3.0\libs\audience-annotations-0.5.0.jar;D:\kafka_2.12-2.3.0\libs\commons-lang3-3.8.1.jar;D:\kafka_2.12-2.3.0\libs\connect-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-basic-auth-extension-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-file-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-json-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-runtime-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-transforms-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\guava-20.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-api-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-locator-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-utils-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jackson-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-core-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-databind-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-dataformat-csv-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-datatype-jdk8-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-base-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-json-provider-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-jaxb-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-paranamer-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-scala_2.12-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka_2.12-2.3.0\libs\jakarta.inject-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka_2.12-2.3.0\libs\javassist-3.22.0-CR2.jar;D:\kafka_2.12-2.3.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka_2.12-2.3.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka_2.12-2.3.0\libs\jaxb-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\jersey-client-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-common-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-hk2-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-server-2.28.jar;D:\kafka_2.12-2.3.0\libs\jetty-client-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-continuation-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-http-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-io-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-security-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-server-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlet-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlets-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-util-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jopt-simple-5.0.4.jar;D:\kafka_2.12-2.3.0\libs\jsr305-3.0.2.jar;D:\kafka_2.12-2.3.0\libs\kafka-clients-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-log4j-appender-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-examples-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-scala_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-test-utils-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-tools-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar.asc;D:\kafka_2.12-2.3.0\libs\log4j-1.2.17.jar;D:\kafka_2.12-2.3.0\libs\lz4-java-1.6.0.jar;D:\kafka_2.12-2.3.0\libs\maven-artifact-3.6.1.jar;D:\kafka_2.12-2.3.0\libs\metrics-core-2.2.0.jar;D:\kafka_2.12-2.3.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka_2.12-2.3.0\libs\paranamer-2.8.jar;D:\kafka_2.12-2.3.0\libs\plexus-utils-3.2.0.jar;D:\kafka_2.12-2.3.0\libs\reflections-0.9.11.jar;D:\kafka_2.12-2.3.0\libs\rocksdbjni-5.18.3.jar;D:\kafka_2.12-2.3.0\libs\scala-library-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\scala-logging_2.12-3.9.0.jar;D:\kafka_2.12-2.3.0\libs\scala-reflect-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\slf4j-api-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\slf4j-log4j12-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\snappy-java-1.1.7.3.jar;D:\kafka_2.12-2.3.0\libs\spotbugs-annotations-3.1.9.jar;D:\kafka_2.12-2.3.0\libs\validation-api-2.0.1.Final.jar;D:\kafka_2.12-2.3.0\libs\zkclient-0.11.jar;D:\kafka_2.12-2.3.0\libs\zookeeper-3.4.14.jar;D:\kafka_2.12-2.3.0\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,119] INFO Server environment:java.library.path=D:\java\jdk\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\Java\jdk1.8.0_73\bin;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;D:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\ManagementStudio\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;D:\confluent-5.2.2\bin;D:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\saksham.aggarwal\AppData\Local\atom\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,123] INFO Server environment:java.io.tmpdir=C:\Users\SAKSHA~1.AGG\AppData\Local\Temp\2\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,124] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,125] INFO Server environment:os.name=Windows Server 2012 R2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,126] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,126] INFO Server environment:os.version=6.3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,127] INFO Server environment:user.name=saksham.aggarwal (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,128] INFO Server environment:user.home=C:\Users\saksham.aggarwal (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,129] INFO Server environment:user.dir=D:\kafka_2.12-2.3.0\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,138] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,139] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,140] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:01:53,157] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-08-14 08:01:53,160] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-14 08:03:26,316] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-14 08:03:26,604] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
java.nio.file.NoSuchFileException: ..\..\config\server\properties
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:85)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.newByteChannel(WindowsFileSystemProvider.java:231)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:370)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:421)
	at java.base/java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:420)
	at java.base/java.nio.file.Files.newInputStream(Files.java:155)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:574)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:51)
	at kafka.Kafka$.main(Kafka.scala:67)
	at kafka.Kafka.main(Kafka.scala)
[2019-08-14 08:03:38,438] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-14 08:03:38,743] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
java.nio.file.NoSuchFileException: ..\..\config\serve.\properties
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:85)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.newByteChannel(WindowsFileSystemProvider.java:231)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:370)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:421)
	at java.base/java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:420)
	at java.base/java.nio.file.Files.newInputStream(Files.java:155)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:574)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:51)
	at kafka.Kafka$.main(Kafka.scala:67)
	at kafka.Kafka.main(Kafka.scala)
[2019-08-14 08:03:51,354] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-14 08:03:51,907] INFO starting (kafka.server.KafkaServer)
[2019-08-14 08:03:51,908] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-14 08:03:51,944] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 08:03:51,950] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,951] INFO Client environment:host.name=SAKSHAMA2012.pacific.costcotravel.com (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,951] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,951] INFO Client environment:java.vendor=AdoptOpenJDK (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,951] INFO Client environment:java.home=D:\java\jdk (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,952] INFO Client environment:java.class.path=..;D:\kafka_2.12-2.3.0\libs\activation-1.1.1.jar;D:\kafka_2.12-2.3.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\argparse4j-0.7.0.jar;D:\kafka_2.12-2.3.0\libs\audience-annotations-0.5.0.jar;D:\kafka_2.12-2.3.0\libs\commons-lang3-3.8.1.jar;D:\kafka_2.12-2.3.0\libs\connect-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-basic-auth-extension-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-file-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-json-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-runtime-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-transforms-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\guava-20.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-api-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-locator-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-utils-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jackson-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-core-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-databind-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-dataformat-csv-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-datatype-jdk8-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-base-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-json-provider-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-jaxb-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-paranamer-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-scala_2.12-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka_2.12-2.3.0\libs\jakarta.inject-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka_2.12-2.3.0\libs\javassist-3.22.0-CR2.jar;D:\kafka_2.12-2.3.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka_2.12-2.3.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka_2.12-2.3.0\libs\jaxb-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\jersey-client-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-common-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-hk2-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-server-2.28.jar;D:\kafka_2.12-2.3.0\libs\jetty-client-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-continuation-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-http-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-io-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-security-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-server-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlet-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlets-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-util-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jopt-simple-5.0.4.jar;D:\kafka_2.12-2.3.0\libs\jsr305-3.0.2.jar;D:\kafka_2.12-2.3.0\libs\kafka-clients-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-log4j-appender-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-examples-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-scala_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-test-utils-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-tools-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar.asc;D:\kafka_2.12-2.3.0\libs\log4j-1.2.17.jar;D:\kafka_2.12-2.3.0\libs\lz4-java-1.6.0.jar;D:\kafka_2.12-2.3.0\libs\maven-artifact-3.6.1.jar;D:\kafka_2.12-2.3.0\libs\metrics-core-2.2.0.jar;D:\kafka_2.12-2.3.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka_2.12-2.3.0\libs\paranamer-2.8.jar;D:\kafka_2.12-2.3.0\libs\plexus-utils-3.2.0.jar;D:\kafka_2.12-2.3.0\libs\reflections-0.9.11.jar;D:\kafka_2.12-2.3.0\libs\rocksdbjni-5.18.3.jar;D:\kafka_2.12-2.3.0\libs\scala-library-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\scala-logging_2.12-3.9.0.jar;D:\kafka_2.12-2.3.0\libs\scala-reflect-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\slf4j-api-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\slf4j-log4j12-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\snappy-java-1.1.7.3.jar;D:\kafka_2.12-2.3.0\libs\spotbugs-annotations-3.1.9.jar;D:\kafka_2.12-2.3.0\libs\validation-api-2.0.1.Final.jar;D:\kafka_2.12-2.3.0\libs\zkclient-0.11.jar;D:\kafka_2.12-2.3.0\libs\zookeeper-3.4.14.jar;D:\kafka_2.12-2.3.0\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,965] INFO Client environment:java.library.path=D:\java\jdk\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\Java\jdk1.8.0_73\bin;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;D:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\ManagementStudio\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;D:\confluent-5.2.2\bin;D:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\saksham.aggarwal\AppData\Local\atom\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,969] INFO Client environment:java.io.tmpdir=C:\Users\SAKSHA~1.AGG\AppData\Local\Temp\2\ (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,970] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,970] INFO Client environment:os.name=Windows Server 2012 R2 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,971] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,972] INFO Client environment:os.version=6.3 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,973] INFO Client environment:user.name=saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,974] INFO Client environment:user.home=C:\Users\saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,974] INFO Client environment:user.dir=D:\kafka_2.12-2.3.0\bin\windows (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,976] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@648c94da (org.apache.zookeeper.ZooKeeper)
[2019-08-14 08:03:51,998] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 08:03:52,003] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-14 08:03:52,007] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-14 08:03:52,007] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61783 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-14 08:03:52,017] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:61783 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:03:52,019] INFO Creating new log file: log.173 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-08-14 08:03:52,027] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10014e807610000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-14 08:03:52,026] INFO Established session 0x10014e807610000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:61783 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 08:03:52,039] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 08:03:52,082] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:create cxid:0x1 zxid:0x174 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:52,099] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:create cxid:0x2 zxid:0x175 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:52,102] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:create cxid:0x3 zxid:0x176 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:52,106] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:create cxid:0x4 zxid:0x177 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:52,114] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:create cxid:0x5 zxid:0x178 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:52,117] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:create cxid:0x6 zxid:0x179 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:52,120] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:create cxid:0x7 zxid:0x17a txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:52,123] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:create cxid:0x8 zxid:0x17b txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:52,126] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:create cxid:0x9 zxid:0x17c txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:52,129] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:create cxid:0xa zxid:0x17d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:52,132] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:create cxid:0xb zxid:0x17e txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:52,135] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:create cxid:0xc zxid:0x17f txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:52,138] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:create cxid:0xd zxid:0x180 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:52,302] INFO Cluster ID = Bx_HGZA6SbGgI2xxf7icgw (kafka.server.KafkaServer)
[2019-08-14 08:03:52,370] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 08:03:52,418] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 08:03:52,483] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 08:03:52,484] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 08:03:52,483] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 08:03:52,535] INFO Loading logs. (kafka.log.LogManager)
[2019-08-14 08:03:52,624] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,640] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,657] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 91 ms (kafka.log.Log)
[2019-08-14 08:03:52,684] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,685] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,687] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 10 ms (kafka.log.Log)
[2019-08-14 08:03:52,698] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,702] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,704] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 4 and log end offset 4 in 13 ms (kafka.log.Log)
[2019-08-14 08:03:52,715] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,717] INFO [ProducerStateManager partition=cwct-producer-test-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-1-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,718] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 10 ms (kafka.log.Log)
[2019-08-14 08:03:52,730] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 34 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,732] INFO [ProducerStateManager partition=cwct-producer-test-2-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-2-0\00000000000000000034.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,733] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 34 in 12 ms (kafka.log.Log)
[2019-08-14 08:03:52,746] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 33 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,748] INFO [ProducerStateManager partition=cwct-producer-test-3-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-3-0\00000000000000000033.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,749] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 33 in 12 ms (kafka.log.Log)
[2019-08-14 08:03:52,758] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,760] INFO [ProducerStateManager partition=cwct-producer-test-4-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-4-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,761] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 9 ms (kafka.log.Log)
[2019-08-14 08:03:52,771] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,773] INFO [ProducerStateManager partition=cwct-producer-test-5-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-5-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,774] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 9 ms (kafka.log.Log)
[2019-08-14 08:03:52,783] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,785] INFO [ProducerStateManager partition=cwct-stream-test-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-stream-test-1-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,786] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:52,795] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,796] INFO [ProducerStateManager partition=test-http-producer-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\test-http-producer-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,797] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:52,806] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,808] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,809] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 9 ms (kafka.log.Log)
[2019-08-14 08:03:52,818] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,819] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,820] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:52,829] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,830] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-10\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,832] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 9 ms (kafka.log.Log)
[2019-08-14 08:03:52,840] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,842] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,843] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 12 in 9 ms (kafka.log.Log)
[2019-08-14 08:03:52,850] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,851] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-08-14 08:03:52,859] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,860] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 08:03:52,869] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,871] INFO [ProducerStateManager partition=__consumer_offsets-14] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-14\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,872] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 9 ms (kafka.log.Log)
[2019-08-14 08:03:52,880] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,881] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-15\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,883] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 9 ms (kafka.log.Log)
[2019-08-14 08:03:52,891] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,893] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,895] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 10 ms (kafka.log.Log)
[2019-08-14 08:03:52,908] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,910] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,911] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 13 ms (kafka.log.Log)
[2019-08-14 08:03:52,919] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,921] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,922] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:52,930] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,934] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,936] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 10 ms (kafka.log.Log)
[2019-08-14 08:03:52,943] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,944] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 08:03:52,951] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,952] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 08:03:52,960] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,962] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,963] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:52,970] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,971] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 08:03:52,978] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,980] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,981] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:52,989] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:52,990] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:52,992] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 9 ms (kafka.log.Log)
[2019-08-14 08:03:52,999] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,000] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 08:03:53,008] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,009] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-26\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,010] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,018] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,020] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-27\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,021] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 12 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,028] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,030] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,031] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,038] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,039] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 08:03:53,047] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,049] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,050] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 12 in 9 ms (kafka.log.Log)
[2019-08-14 08:03:53,057] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,059] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,060] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,067] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,068] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,069] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 7 ms (kafka.log.Log)
[2019-08-14 08:03:53,076] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,077] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-08-14 08:03:53,084] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,086] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-33\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,087] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,094] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,096] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,097] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,105] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,106] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-35\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,107] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,115] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,137] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,138] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 28 ms (kafka.log.Log)
[2019-08-14 08:03:53,146] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,148] INFO [ProducerStateManager partition=__consumer_offsets-37] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-37\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,149] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,156] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,158] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-38\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,159] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,166] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,167] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 08:03:53,174] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,175] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 08:03:53,181] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,182] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-08-14 08:03:53,189] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,190] INFO [ProducerStateManager partition=__consumer_offsets-41] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-41\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,191] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 7 ms (kafka.log.Log)
[2019-08-14 08:03:53,199] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 19 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,201] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000019.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,202] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 19 in 9 ms (kafka.log.Log)
[2019-08-14 08:03:53,209] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,210] INFO [ProducerStateManager partition=__consumer_offsets-43] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-43\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,211] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 7 ms (kafka.log.Log)
[2019-08-14 08:03:53,218] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,219] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 08:03:53,226] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,228] INFO [ProducerStateManager partition=__consumer_offsets-45] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-45\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,229] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,235] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,248] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,249] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 19 ms (kafka.log.Log)
[2019-08-14 08:03:53,256] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,257] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 08:03:53,263] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,265] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-48\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,266] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,273] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,274] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,275] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 7 ms (kafka.log.Log)
[2019-08-14 08:03:53,283] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,284] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,285] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,292] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,293] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-6\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,294] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 7 ms (kafka.log.Log)
[2019-08-14 08:03:53,301] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,303] INFO [ProducerStateManager partition=__consumer_offsets-7] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-7\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,304] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,310] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,312] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-8\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,313] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 7 ms (kafka.log.Log)
[2019-08-14 08:03:53,320] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-08-14 08:03:53,322] INFO [ProducerStateManager partition=__consumer_offsets-9] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 08:03:53,323] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 8 ms (kafka.log.Log)
[2019-08-14 08:03:53,327] INFO Logs loading complete in 792 ms. (kafka.log.LogManager)
[2019-08-14 08:03:53,349] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-14 08:03:53,351] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-14 08:03:53,699] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-14 08:03:53,733] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-08-14 08:03:53,735] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-08-14 08:03:53,762] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 08:03:53,763] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 08:03:53,763] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 08:03:53,764] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 08:03:53,776] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-14 08:03:53,827] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-14 08:03:53,849] INFO Stat of the created znode at /brokers/ids/0 is: 385,385,1565795033841,1565795033841,1,0,0,72080580826693632,244,0,385
 (kafka.zk.KafkaZkClient)
[2019-08-14 08:03:53,850] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(SAKSHAMA2012.pacific.costcotravel.com,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 385 (kafka.zk.KafkaZkClient)
[2019-08-14 08:03:53,917] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 08:03:53,921] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 08:03:53,921] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 08:03:53,947] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:53,950] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:53,955] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:53,969] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:10000,blockEndProducerId:10999) by writing to Zk with path version 11 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-14 08:03:54,000] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-14 08:03:54,003] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-14 08:03:54,004] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-14 08:03:54,049] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-14 08:03:54,096] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-14 08:03:54,108] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-14 08:03:54,114] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-14 08:03:54,114] INFO Kafka startTimeMs: 1565795034098 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-14 08:03:54,125] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-08-14 08:03:54,142] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:multi cxid:0x8b zxid:0x184 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:03:54,195] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, cwct-producer-test-4-0, __consumer_offsets-30, cwct-producer-test-1-0, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, test-http-producer-0, __consumer_offsets-31, __consumer_offsets-36, cwct-producer-test-5-0, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, cwct-producer-test-2-0, __consumer_offsets-15, __consumer_offsets-24, cwct-stream-test-1-0, 476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, 476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, 476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, cwct-producer-test-3-0, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-08-14 08:03:54,211] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 5 (kafka.cluster.Replica)
[2019-08-14 08:03:54,214] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,229] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:03:54,230] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,238] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 5 (kafka.cluster.Replica)
[2019-08-14 08:03:54,239] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,242] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-14 08:03:54,243] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,247] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-14 08:03:54,248] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,252] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-14 08:03:54,252] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,255] INFO Replica loaded for partition cwct-producer-test-3-0 with initial high watermark 33 (kafka.cluster.Replica)
[2019-08-14 08:03:54,256] INFO [Partition cwct-producer-test-3-0 broker=0] cwct-producer-test-3-0 starts at Leader Epoch 0 from offset 33. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,260] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,261] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,266] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 19 (kafka.cluster.Replica)
[2019-08-14 08:03:54,266] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 19. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,269] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:03:54,270] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,275] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 8 (kafka.cluster.Replica)
[2019-08-14 08:03:54,276] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,279] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-14 08:03:54,280] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,282] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:03:54,283] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,289] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:03:54,290] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,296] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 9 (kafka.cluster.Replica)
[2019-08-14 08:03:54,297] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 9. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,300] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,301] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,304] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-14 08:03:54,305] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,307] INFO Replica loaded for partition cwct-producer-test-5-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-14 08:03:54,308] INFO [Partition cwct-producer-test-5-0 broker=0] cwct-producer-test-5-0 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,310] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,311] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,314] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-14 08:03:54,315] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,319] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 12 (kafka.cluster.Replica)
[2019-08-14 08:03:54,321] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 12. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,325] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,325] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,328] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,329] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,332] INFO Replica loaded for partition 476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,333] INFO [Partition 476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 broker=0] 476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,336] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 12 (kafka.cluster.Replica)
[2019-08-14 08:03:54,337] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 12. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,341] INFO Replica loaded for partition cwct-producer-test-2-0 with initial high watermark 34 (kafka.cluster.Replica)
[2019-08-14 08:03:54,342] INFO [Partition cwct-producer-test-2-0 broker=0] cwct-producer-test-2-0 starts at Leader Epoch 0 from offset 34. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,345] INFO Replica loaded for partition test-http-producer-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-14 08:03:54,345] INFO [Partition test-http-producer-0 broker=0] test-http-producer-0 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,348] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 9 (kafka.cluster.Replica)
[2019-08-14 08:03:54,349] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 9. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,355] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,355] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,358] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-14 08:03:54,359] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,362] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 5 (kafka.cluster.Replica)
[2019-08-14 08:03:54,362] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,365] INFO Replica loaded for partition 476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-08-14 08:03:54,366] INFO [Partition 476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0 broker=0] 476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0 starts at Leader Epoch 0 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,371] INFO Replica loaded for partition cwct-stream-test-1-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,372] INFO [Partition cwct-stream-test-1-0 broker=0] cwct-stream-test-1-0 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,375] INFO Replica loaded for partition 476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,375] INFO [Partition 476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0 broker=0] 476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,378] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-14 08:03:54,379] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,382] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:03:54,383] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,389] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:03:54,390] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,395] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-14 08:03:54,395] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,398] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 11 (kafka.cluster.Replica)
[2019-08-14 08:03:54,398] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 11. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,401] INFO Replica loaded for partition cwct-producer-test-1-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,401] INFO [Partition cwct-producer-test-1-0 broker=0] cwct-producer-test-1-0 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,404] INFO Replica loaded for partition cwct-producer-test-4-0 with initial high watermark 10 (kafka.cluster.Replica)
[2019-08-14 08:03:54,405] INFO [Partition cwct-producer-test-4-0 broker=0] cwct-producer-test-4-0 starts at Leader Epoch 0 from offset 10. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,407] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,408] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,410] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 5 (kafka.cluster.Replica)
[2019-08-14 08:03:54,411] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,414] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:03:54,414] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,419] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-14 08:03:54,420] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,423] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 11 (kafka.cluster.Replica)
[2019-08-14 08:03:54,423] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 11. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,426] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:03:54,426] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,431] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,432] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,434] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,435] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,437] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-14 08:03:54,438] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,440] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-14 08:03:54,441] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,443] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:03:54,445] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,452] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-14 08:03:54,453] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,456] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:03:54,456] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,461] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-14 08:03:54,461] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,464] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:03:54,464] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,469] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-14 08:03:54,469] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,472] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:03:54,472] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,477] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 12 (kafka.cluster.Replica)
[2019-08-14 08:03:54,480] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 12. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,482] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:03:54,483] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:03:54,493] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,495] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,496] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,496] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,498] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,498] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,499] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,500] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,501] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,501] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,502] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,503] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,504] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,504] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,505] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,506] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,507] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,511] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,508] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,512] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,515] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,516] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,517] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,517] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,518] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,519] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,520] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,520] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,521] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,522] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,523] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,523] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,524] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,526] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,527] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,528] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,530] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,530] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,531] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,532] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,534] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,535] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,546] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,547] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,546] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-84666 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,547] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,549] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 35 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,549] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,550] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,551] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,552] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,553] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,559] INFO [GroupCoordinator 0]: Loading group metadata for 99a7a2d7-b881-4b21-949a-9f7dbe3e66eb with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,563] INFO [GroupCoordinator 0]: Loading group metadata for 7d54ebce-548e-4745-8484-d2f476c9d7c9 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,565] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,575] INFO [GroupCoordinator 0]: Loading group metadata for 83871b28-8bfd-45c4-b16d-19886f2d6f5f with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,576] INFO [GroupCoordinator 0]: Loading group metadata for 41f6b789-9212-492b-bc11-23883cbf1163 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,577] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,587] INFO [GroupCoordinator 0]: Loading group metadata for 1a5c5da2-a952-4adc-ac86-850f82ae2599 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,588] INFO [GroupCoordinator 0]: Loading group metadata for a5329e39-99e4-44b9-a5f5-7ccdd2b42d86 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,589] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,590] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,596] INFO [GroupCoordinator 0]: Loading group metadata for cde7c855-a06f-497d-903f-097183f75994 with generation 4 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,597] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,604] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,605] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,611] INFO [GroupCoordinator 0]: Loading group metadata for 70fa0ac9-4f76-47e9-8949-a552b8a75c36 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,620] INFO [GroupCoordinator 0]: Loading group metadata for b03bba4f-fe16-4305-a7ee-046517712ad6 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,621] INFO [GroupCoordinator 0]: Loading group metadata for 10321353-3dbd-49d0-a674-f44c3c51f7ce with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,621] INFO [GroupCoordinator 0]: Loading group metadata for a372c615-3368-4c10-a8c4-9fa672daaf8c with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,622] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,629] INFO [GroupCoordinator 0]: Loading group metadata for e72487eb-d7af-4f0c-9726-6382507bad23 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,630] INFO [GroupCoordinator 0]: Loading group metadata for 9b021163-3bb4-4a5e-83f7-9d126194215d with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,630] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,632] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,642] INFO [GroupCoordinator 0]: Loading group metadata for 4addd770-41e9-4b12-bc64-90b334d3a555 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,642] INFO [GroupCoordinator 0]: Loading group metadata for 58f4bd85-3714-41d5-ad16-36787b8cd1b8 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,643] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,644] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,651] INFO [GroupCoordinator 0]: Loading group metadata for eadc6b3b-a9ff-47b5-879c-5d264e54da7b with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,652] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,660] INFO [GroupCoordinator 0]: Loading group metadata for 3ebded0d-744c-4f02-83fd-84797e18e960 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,661] INFO [GroupCoordinator 0]: Loading group metadata for 6075fb3c-10b5-4587-a4dd-3cb629eced6d with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,663] INFO [GroupCoordinator 0]: Loading group metadata for 217417cb-8e86-4d4f-b924-207b39324532 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,665] INFO [GroupCoordinator 0]: Loading group metadata for 8039d2cb-de11-4a58-993f-9a2bfabe96c6 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,675] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 23 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,682] INFO [GroupCoordinator 0]: Loading group metadata for 0b57d019-ee4a-4bd4-9327-6afe65adae4c with generation 4 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,683] INFO [GroupCoordinator 0]: Loading group metadata for 5f059d25-a6c4-485c-a1f0-da531fb982fb with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,684] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,690] INFO [GroupCoordinator 0]: Loading group metadata for c52b9a52-db2c-4e14-8bf7-42f0cfcd605e with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,691] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-62718 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,692] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,698] INFO [GroupCoordinator 0]: Loading group metadata for 467d9719-fafd-4b42-9d56-1b04f494b27f with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,699] INFO [GroupCoordinator 0]: Loading group metadata for 500a2887-c447-451b-a53c-44e83fcb6135 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,700] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,707] INFO [GroupCoordinator 0]: Loading group metadata for 67c535d2-a85f-4e8d-96c7-9d5989524b94 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,708] INFO [GroupCoordinator 0]: Loading group metadata for 969bf8e9-70da-480c-94d2-f3d7747fa85a with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,708] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,714] INFO [GroupCoordinator 0]: Loading group metadata for 3e9993c3-51ae-4713-b0c4-250c42e294fe with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,715] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,716] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,723] INFO [GroupCoordinator 0]: Loading group metadata for adccfa07-b143-47ef-a597-888013a8aabc with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,723] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,724] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,732] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,739] INFO [GroupCoordinator 0]: Loading group metadata for a6f03b60-e080-446f-9b9e-225747f9bfbf with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,740] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,741] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,746] INFO [GroupCoordinator 0]: Loading group metadata for 8d7657ac-2cde-486f-8a5a-8284b657dc50 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,747] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,754] INFO [GroupCoordinator 0]: Loading group metadata for fd4baf93-84df-4861-9452-d50fd7854516 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,755] INFO [GroupCoordinator 0]: Loading group metadata for 73a9c9af-a363-4033-a2c2-a3b64a43e466 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,756] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,758] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,767] INFO [GroupCoordinator 0]: Loading group metadata for 6458bb10-fc36-4795-9451-eb212b69c0bb with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,768] INFO [GroupCoordinator 0]: Loading group metadata for 5caa3fe3-aee1-4e52-a534-d0405575eeca with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,768] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,775] INFO [GroupCoordinator 0]: Loading group metadata for ee145751-60dc-4f12-8e9e-f2dee26f58b7 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,776] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,782] INFO [GroupCoordinator 0]: Loading group metadata for 630599f9-e77b-4f0e-be4d-3f5e8d350c9f with generation 4 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,783] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,789] INFO [GroupCoordinator 0]: Loading group metadata for b37f080e-7f68-4e68-b91a-0e77adb90cd1 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,790] INFO [GroupCoordinator 0]: Loading group metadata for 2abe4630-d862-4924-bbdd-6fb8ccb4e6f0 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,791] INFO [GroupCoordinator 0]: Loading group metadata for 247dc551-f847-404a-951e-10c7dc02768a with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,792] INFO [GroupCoordinator 0]: Loading group metadata for 86126fa7-4b1b-468b-be9e-5820287e3c23 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,793] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,800] INFO [GroupCoordinator 0]: Loading group metadata for 351c84b3-631e-459f-aff7-9ce429c86967 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,800] INFO [GroupCoordinator 0]: Loading group metadata for 5fb53b73-be9e-4c02-89a1-346eec187485 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,801] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,807] INFO [GroupCoordinator 0]: Loading group metadata for 4a2eb38d-b3d2-4fc1-86f1-ea3eb79f9cdf with generation 4 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,808] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,809] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,815] INFO [GroupCoordinator 0]: Loading group metadata for 88158b6b-a5ab-4743-b0da-832861e88343 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,816] INFO [GroupCoordinator 0]: Loading group metadata for 79d857e9-d81e-4b0c-9d2d-eb4af33962ff with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,816] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,822] INFO [GroupCoordinator 0]: Loading group metadata for 476947f3-f64f-40a5-aa43-fea377e6df90 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,828] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,834] INFO [GroupCoordinator 0]: Loading group metadata for 53961830-74d0-4397-8388-9a2ff99995ba with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,834] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,835] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,842] INFO [GroupCoordinator 0]: Loading group metadata for 3730e0a7-f3e4-4787-84a5-94d22142fe9d with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,843] INFO [GroupCoordinator 0]: Loading group metadata for 0e90a5c8-3f0c-4e4f-b5fa-ff9aeb22075a with generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,844] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,849] INFO [GroupCoordinator 0]: Loading group metadata for 55ca25b8-e91a-4ab0-b919-92b6b97d451d with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,850] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,856] INFO [GroupCoordinator 0]: Loading group metadata for 9061d92e-2aed-4794-9291-88c160ffdd7f with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,857] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,863] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,870] INFO [GroupCoordinator 0]: Loading group metadata for bc3f8caf-6103-44fc-b7ad-a09941512276 with generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,871] INFO [GroupCoordinator 0]: Loading group metadata for 9eb5fa52-168a-407e-82de-4a74ad7ac378 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,871] INFO [GroupCoordinator 0]: Loading group metadata for f44e0ef8-a416-4c47-a115-7a10fe87c738 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,872] INFO [GroupCoordinator 0]: Loading group metadata for 0bafbccd-e53d-4aa1-bb64-e235cfd3bb24 with generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,873] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:03:54,879] INFO [GroupCoordinator 0]: Loading group metadata for a3a24764-4366-4aec-bd20-bbe0386ce2a9 with generation 4 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:03:54,880] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:04:04,832] INFO [GroupCoordinator 0]: Member 476947f3-f64f-40a5-aa43-fea377e6df90-2da9bfeb-1c08-4a2f-852d-ea2d2630de10-StreamThread-1-consumer-61c90a8d-70de-4292-9f9c-169750e38862 in group 476947f3-f64f-40a5-aa43-fea377e6df90 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:04:04,836] INFO [GroupCoordinator 0]: Preparing to rebalance group 476947f3-f64f-40a5-aa43-fea377e6df90 in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: removing member 476947f3-f64f-40a5-aa43-fea377e6df90-2da9bfeb-1c08-4a2f-852d-ea2d2630de10-StreamThread-1-consumer-61c90a8d-70de-4292-9f9c-169750e38862 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:04:04,840] INFO [GroupCoordinator 0]: Group 476947f3-f64f-40a5-aa43-fea377e6df90 with generation 2 is now empty (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:05:36,592] INFO Creating topic cwct-stream-input-test-1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 08:05:36,595] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0xcd zxid:0x185 txntype:-1 reqpath:n/a Error Path:/config/topics/cwct-stream-input-test-1 Error:KeeperErrorCode = NoNode for /config/topics/cwct-stream-input-test-1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:05:36,625] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(cwct-stream-input-test-1-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 08:05:36,631] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:05:36,633] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-08-14 08:05:36,635] INFO Created log for partition cwct-stream-input-test-1-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 08:05:36,639] INFO [Partition cwct-stream-input-test-1-0 broker=0] No checkpointed highwatermark is found for partition cwct-stream-input-test-1-0 (kafka.cluster.Partition)
[2019-08-14 08:05:36,640] INFO Replica loaded for partition cwct-stream-input-test-1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:05:36,641] INFO [Partition cwct-stream-input-test-1-0 broker=0] cwct-stream-input-test-1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:05:47,124] INFO Creating topic cwct-stream-output-test-1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 08:05:47,126] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0xd7 zxid:0x18b txntype:-1 reqpath:n/a Error Path:/config/topics/cwct-stream-output-test-1 Error:KeeperErrorCode = NoNode for /config/topics/cwct-stream-output-test-1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:05:47,147] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(cwct-stream-output-test-1-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 08:05:47,152] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:05:47,153] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-08-14 08:05:47,154] INFO Created log for partition cwct-stream-output-test-1-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 08:05:47,158] INFO [Partition cwct-stream-output-test-1-0 broker=0] No checkpointed highwatermark is found for partition cwct-stream-output-test-1-0 (kafka.cluster.Partition)
[2019-08-14 08:05:47,158] INFO Replica loaded for partition cwct-stream-output-test-1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:05:47,159] INFO [Partition cwct-stream-output-test-1-0 broker=0] cwct-stream-output-test-1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:13:53,957] INFO [GroupMetadataManager brokerId=0] Group console-consumer-62718 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:13:53,961] INFO [GroupMetadataManager brokerId=0] Group console-consumer-84666 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:13:53,962] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:23:53,952] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:30:05,256] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-61964 in state PreparingRebalance with old generation 0 (__consumer_offsets-47) (reason: Adding new member consumer-1-c12b3bad-af6a-4db3-921f-61b0cb63e56f with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:30:05,261] INFO [GroupCoordinator 0]: Stabilized group console-consumer-61964 generation 1 (__consumer_offsets-47) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:30:05,276] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-61964 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:30:22,627] INFO [GroupCoordinator 0]: Member consumer-1-c12b3bad-af6a-4db3-921f-61b0cb63e56f in group console-consumer-61964 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:30:22,628] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-61964 in state PreparingRebalance with old generation 1 (__consumer_offsets-47) (reason: removing member consumer-1-c12b3bad-af6a-4db3-921f-61b0cb63e56f on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:30:22,629] INFO [GroupCoordinator 0]: Group console-consumer-61964 with generation 2 is now empty (__consumer_offsets-47) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:30:39,447] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-90374 in state PreparingRebalance with old generation 0 (__consumer_offsets-34) (reason: Adding new member consumer-1-1a52aaaf-f2c1-4b28-a1fd-49667a204b5f with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:30:39,449] INFO [GroupCoordinator 0]: Stabilized group console-consumer-90374 generation 1 (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:30:39,459] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-90374 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:30:53,650] INFO [GroupCoordinator 0]: Member consumer-1-1a52aaaf-f2c1-4b28-a1fd-49667a204b5f in group console-consumer-90374 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:30:53,651] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-90374 in state PreparingRebalance with old generation 1 (__consumer_offsets-34) (reason: removing member consumer-1-1a52aaaf-f2c1-4b28-a1fd-49667a204b5f on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:30:53,652] INFO [GroupCoordinator 0]: Group console-consumer-90374 with generation 2 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:31:13,229] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-23788 in state PreparingRebalance with old generation 0 (__consumer_offsets-39) (reason: Adding new member consumer-1-46f78582-6ba4-4cfa-a51f-98f25803ade4 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:31:13,231] INFO [GroupCoordinator 0]: Stabilized group console-consumer-23788 generation 1 (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:31:13,243] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-23788 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:31:18,586] INFO [GroupCoordinator 0]: Member consumer-1-46f78582-6ba4-4cfa-a51f-98f25803ade4 in group console-consumer-23788 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:31:18,587] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-23788 in state PreparingRebalance with old generation 1 (__consumer_offsets-39) (reason: removing member consumer-1-46f78582-6ba4-4cfa-a51f-98f25803ade4 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:31:18,588] INFO [GroupCoordinator 0]: Group console-consumer-23788 with generation 2 is now empty (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:31:29,712] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-3806 in state PreparingRebalance with old generation 0 (__consumer_offsets-16) (reason: Adding new member consumer-1-1bbb3db0-68b0-4914-a3e1-aca6ca999f34 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:31:29,714] INFO [GroupCoordinator 0]: Stabilized group console-consumer-3806 generation 1 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:31:29,724] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-3806 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:33:18,282] INFO Creating topic cwct-stream-1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 08:33:18,284] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0xe1 zxid:0x191 txntype:-1 reqpath:n/a Error Path:/config/topics/cwct-stream-1 Error:KeeperErrorCode = NoNode for /config/topics/cwct-stream-1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:33:18,304] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(cwct-stream-1-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 08:33:18,309] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:33:18,310] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-08-14 08:33:18,311] INFO Created log for partition cwct-stream-1-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 08:33:18,315] INFO [Partition cwct-stream-1-0 broker=0] No checkpointed highwatermark is found for partition cwct-stream-1-0 (kafka.cluster.Partition)
[2019-08-14 08:33:18,315] INFO Replica loaded for partition cwct-stream-1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:33:18,316] INFO [Partition cwct-stream-1-0 broker=0] cwct-stream-1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:33:53,951] INFO [GroupMetadataManager brokerId=0] Group console-consumer-61964 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:33:53,954] INFO [GroupMetadataManager brokerId=0] Group console-consumer-90374 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:33:53,956] INFO [GroupMetadataManager brokerId=0] Group console-consumer-23788 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:33:53,957] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:38:35,356] INFO [GroupCoordinator 0]: Preparing to rebalance group f715541f-3980-4394-9320-ef89bba0568d in state PreparingRebalance with old generation 0 (__consumer_offsets-13) (reason: Adding new member f715541f-3980-4394-9320-ef89bba0568d-345a5061-f36c-4a58-92a2-d4871cad50d6-StreamThread-1-consumer-c4fd97cf-481d-4609-b63b-8c1de5696a08 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:38:35,358] INFO [GroupCoordinator 0]: Stabilized group f715541f-3980-4394-9320-ef89bba0568d generation 1 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:38:35,379] INFO Creating topic f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 08:38:35,382] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0xeb zxid:0x197 txntype:-1 reqpath:n/a Error Path:/config/topics/f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog Error:KeeperErrorCode = NoNode for /config/topics/f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:38:35,402] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 08:38:35,408] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:38:35,409] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-08-14 08:38:35,411] INFO Created log for partition f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 08:38:35,416] INFO [Partition f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 broker=0] No checkpointed highwatermark is found for partition f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 (kafka.cluster.Partition)
[2019-08-14 08:38:35,417] INFO Replica loaded for partition f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:38:35,418] INFO [Partition f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 broker=0] f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:38:35,437] INFO [GroupCoordinator 0]: Assignment received from leader for group f715541f-3980-4394-9320-ef89bba0568d for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:40:15,456] INFO [GroupCoordinator 0]: Member f715541f-3980-4394-9320-ef89bba0568d-345a5061-f36c-4a58-92a2-d4871cad50d6-StreamThread-1-consumer-c4fd97cf-481d-4609-b63b-8c1de5696a08 in group f715541f-3980-4394-9320-ef89bba0568d has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:40:15,457] INFO [GroupCoordinator 0]: Preparing to rebalance group f715541f-3980-4394-9320-ef89bba0568d in state PreparingRebalance with old generation 1 (__consumer_offsets-13) (reason: removing member f715541f-3980-4394-9320-ef89bba0568d-345a5061-f36c-4a58-92a2-d4871cad50d6-StreamThread-1-consumer-c4fd97cf-481d-4609-b63b-8c1de5696a08 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:40:15,459] INFO [GroupCoordinator 0]: Group f715541f-3980-4394-9320-ef89bba0568d with generation 2 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:41:13,826] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-68574 in state PreparingRebalance with old generation 0 (__consumer_offsets-21) (reason: Adding new member consumer-1-6eba7fa2-e704-4b6e-a4b7-4c1addd9b474 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:41:13,828] INFO [GroupCoordinator 0]: Stabilized group console-consumer-68574 generation 1 (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:41:13,838] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-68574 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:41:22,492] INFO [GroupCoordinator 0]: Preparing to rebalance group dc884088-7f9b-49bb-9782-31f115e6c1d6 in state PreparingRebalance with old generation 0 (__consumer_offsets-16) (reason: Adding new member dc884088-7f9b-49bb-9782-31f115e6c1d6-bc87cb4e-82de-40ea-b83f-291e18b0c998-StreamThread-1-consumer-f3217d34-5724-4a62-b5ca-90869325b197 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:41:22,496] INFO [GroupCoordinator 0]: Stabilized group dc884088-7f9b-49bb-9782-31f115e6c1d6 generation 1 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:41:22,526] INFO Creating topic dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 08:41:22,528] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0xf5 zxid:0x19d txntype:-1 reqpath:n/a Error Path:/config/topics/dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog Error:KeeperErrorCode = NoNode for /config/topics/dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:41:22,569] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 08:41:22,581] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:41:22,583] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 08:41:22,585] INFO Created log for partition dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 08:41:22,588] INFO [Partition dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 broker=0] No checkpointed highwatermark is found for partition dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 (kafka.cluster.Partition)
[2019-08-14 08:41:22,589] INFO Replica loaded for partition dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:41:22,590] INFO [Partition dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 broker=0] dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:41:22,609] INFO [GroupCoordinator 0]: Assignment received from leader for group dc884088-7f9b-49bb-9782-31f115e6c1d6 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:42:14,624] INFO [GroupCoordinator 0]: Member dc884088-7f9b-49bb-9782-31f115e6c1d6-bc87cb4e-82de-40ea-b83f-291e18b0c998-StreamThread-1-consumer-f3217d34-5724-4a62-b5ca-90869325b197 in group dc884088-7f9b-49bb-9782-31f115e6c1d6 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:42:14,625] INFO [GroupCoordinator 0]: Preparing to rebalance group dc884088-7f9b-49bb-9782-31f115e6c1d6 in state PreparingRebalance with old generation 1 (__consumer_offsets-16) (reason: removing member dc884088-7f9b-49bb-9782-31f115e6c1d6-bc87cb4e-82de-40ea-b83f-291e18b0c998-StreamThread-1-consumer-f3217d34-5724-4a62-b5ca-90869325b197 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:42:14,627] INFO [GroupCoordinator 0]: Group dc884088-7f9b-49bb-9782-31f115e6c1d6 with generation 2 is now empty (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:43:53,951] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:45:39,419] INFO [GroupCoordinator 0]: Member consumer-1-6eba7fa2-e704-4b6e-a4b7-4c1addd9b474 in group console-consumer-68574 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:45:39,420] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-68574 in state PreparingRebalance with old generation 1 (__consumer_offsets-21) (reason: removing member consumer-1-6eba7fa2-e704-4b6e-a4b7-4c1addd9b474 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:45:39,421] INFO [GroupCoordinator 0]: Group console-consumer-68574 with generation 2 is now empty (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:47:01,128] INFO Creating topic key-based-events-1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 08:47:01,129] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0xff zxid:0x1a3 txntype:-1 reqpath:n/a Error Path:/config/topics/key-based-events-1 Error:KeeperErrorCode = NoNode for /config/topics/key-based-events-1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:47:01,145] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(key-based-events-1-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 08:47:01,149] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:47:01,150] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-08-14 08:47:01,152] INFO Created log for partition key-based-events-1-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 08:47:01,155] INFO [Partition key-based-events-1-0 broker=0] No checkpointed highwatermark is found for partition key-based-events-1-0 (kafka.cluster.Partition)
[2019-08-14 08:47:01,156] INFO Replica loaded for partition key-based-events-1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:47:01,156] INFO [Partition key-based-events-1-0 broker=0] key-based-events-1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:53:53,950] INFO [GroupMetadataManager brokerId=0] Group console-consumer-68574 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:53:53,953] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 08:56:14,563] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-59275 in state PreparingRebalance with old generation 0 (__consumer_offsets-9) (reason: Adding new member consumer-1-44f5adf0-a022-4d24-8c95-0348c9e3243e with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:56:14,566] INFO [GroupCoordinator 0]: Stabilized group console-consumer-59275 generation 1 (__consumer_offsets-9) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:56:14,575] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-59275 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:56:20,748] INFO [GroupCoordinator 0]: Preparing to rebalance group 40b5a322-1084-4d88-9035-5640d6e2dddb in state PreparingRebalance with old generation 0 (__consumer_offsets-27) (reason: Adding new member 40b5a322-1084-4d88-9035-5640d6e2dddb-64794ddd-fc43-45df-8813-ee12cd4338e6-StreamThread-1-consumer-fc7eaf5f-be10-4d7b-8ed6-5b28cf80b7e2 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:56:20,750] INFO [GroupCoordinator 0]: Stabilized group 40b5a322-1084-4d88-9035-5640d6e2dddb generation 1 (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:56:20,770] INFO Creating topic 40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 08:56:20,771] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x109 zxid:0x1a9 txntype:-1 reqpath:n/a Error Path:/config/topics/40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog Error:KeeperErrorCode = NoNode for /config/topics/40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 08:56:20,788] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 08:56:20,794] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 08:56:20,795] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-08-14 08:56:20,797] INFO Created log for partition 40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 08:56:20,800] INFO [Partition 40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0 broker=0] No checkpointed highwatermark is found for partition 40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0 (kafka.cluster.Partition)
[2019-08-14 08:56:20,802] INFO Replica loaded for partition 40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 08:56:20,803] INFO [Partition 40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0 broker=0] 40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 08:56:20,839] INFO [GroupCoordinator 0]: Assignment received from leader for group 40b5a322-1084-4d88-9035-5640d6e2dddb for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:58:00,917] INFO [GroupCoordinator 0]: Member 40b5a322-1084-4d88-9035-5640d6e2dddb-64794ddd-fc43-45df-8813-ee12cd4338e6-StreamThread-1-consumer-fc7eaf5f-be10-4d7b-8ed6-5b28cf80b7e2 in group 40b5a322-1084-4d88-9035-5640d6e2dddb has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:58:00,918] INFO [GroupCoordinator 0]: Preparing to rebalance group 40b5a322-1084-4d88-9035-5640d6e2dddb in state PreparingRebalance with old generation 1 (__consumer_offsets-27) (reason: removing member 40b5a322-1084-4d88-9035-5640d6e2dddb-64794ddd-fc43-45df-8813-ee12cd4338e6-StreamThread-1-consumer-fc7eaf5f-be10-4d7b-8ed6-5b28cf80b7e2 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 08:58:00,920] INFO [GroupCoordinator 0]: Group 40b5a322-1084-4d88-9035-5640d6e2dddb with generation 2 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:00:14,456] INFO [GroupCoordinator 0]: Preparing to rebalance group 79964e0b-38f1-4dcb-bf16-876455cd1e42 in state PreparingRebalance with old generation 0 (__consumer_offsets-20) (reason: Adding new member 79964e0b-38f1-4dcb-bf16-876455cd1e42-61d0959d-5d6c-490c-88ec-490d4de0dc2f-StreamThread-1-consumer-283a8a88-894a-4aad-8d67-5cb071dc3df5 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:00:14,462] INFO [GroupCoordinator 0]: Stabilized group 79964e0b-38f1-4dcb-bf16-876455cd1e42 generation 1 (__consumer_offsets-20) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:00:14,484] INFO Creating topic 79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:00:14,487] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x113 zxid:0x1af txntype:-1 reqpath:n/a Error Path:/config/topics/79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog Error:KeeperErrorCode = NoNode for /config/topics/79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:00:14,519] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:00:14,528] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:00:14,530] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 09:00:14,534] INFO Created log for partition 79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:00:14,558] INFO [Partition 79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0 broker=0] No checkpointed highwatermark is found for partition 79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0 (kafka.cluster.Partition)
[2019-08-14 09:00:14,559] INFO Replica loaded for partition 79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:00:14,560] INFO [Partition 79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0 broker=0] 79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:00:14,576] INFO [GroupCoordinator 0]: Assignment received from leader for group 79964e0b-38f1-4dcb-bf16-876455cd1e42 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:02:51,608] INFO [GroupCoordinator 0]: Member 79964e0b-38f1-4dcb-bf16-876455cd1e42-61d0959d-5d6c-490c-88ec-490d4de0dc2f-StreamThread-1-consumer-283a8a88-894a-4aad-8d67-5cb071dc3df5 in group 79964e0b-38f1-4dcb-bf16-876455cd1e42 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:02:51,609] INFO [GroupCoordinator 0]: Preparing to rebalance group 79964e0b-38f1-4dcb-bf16-876455cd1e42 in state PreparingRebalance with old generation 1 (__consumer_offsets-20) (reason: removing member 79964e0b-38f1-4dcb-bf16-876455cd1e42-61d0959d-5d6c-490c-88ec-490d4de0dc2f-StreamThread-1-consumer-283a8a88-894a-4aad-8d67-5cb071dc3df5 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:02:51,611] INFO [GroupCoordinator 0]: Group 79964e0b-38f1-4dcb-bf16-876455cd1e42 with generation 2 is now empty (__consumer_offsets-20) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:03:54,015] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 09:06:20,138] INFO [GroupCoordinator 0]: Preparing to rebalance group 64907477-1a30-44ca-aba9-921bdb9571ca in state PreparingRebalance with old generation 0 (__consumer_offsets-20) (reason: Adding new member 64907477-1a30-44ca-aba9-921bdb9571ca-421193fa-8707-4adc-babd-4bbda809fd3c-StreamThread-1-consumer-734749e1-9e14-4122-b300-b247d94d9cb3 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:06:20,150] INFO [GroupCoordinator 0]: Stabilized group 64907477-1a30-44ca-aba9-921bdb9571ca generation 1 (__consumer_offsets-20) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:06:20,178] INFO Creating topic 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition with configuration {cleanup.policy=delete, segment.bytes=52428800, retention.ms=-1} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:06:20,180] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x11d zxid:0x1b5 txntype:-1 reqpath:n/a Error Path:/config/topics/64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition Error:KeeperErrorCode = NoNode for /config/topics/64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:06:20,210] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:06:20,226] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:06:20,228] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-08-14 09:06:20,230] INFO Created log for partition 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, retention.ms -> -1, segment.bytes -> 52428800, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:06:20,233] INFO [Partition 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 broker=0] No checkpointed highwatermark is found for partition 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 (kafka.cluster.Partition)
[2019-08-14 09:06:20,234] INFO Replica loaded for partition 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:06:20,235] INFO [Partition 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 broker=0] 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:06:20,248] INFO Creating topic 64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:06:20,250] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x127 zxid:0x1bb txntype:-1 reqpath:n/a Error Path:/config/topics/64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog Error:KeeperErrorCode = NoNode for /config/topics/64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:06:20,264] INFO Creating topic 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:06:20,270] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x130 zxid:0x1c1 txntype:-1 reqpath:n/a Error Path:/config/topics/64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog Error:KeeperErrorCode = NoNode for /config/topics/64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:06:20,269] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:06:20,277] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:06:20,279] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-08-14 09:06:20,281] INFO Created log for partition 64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:06:20,286] INFO [Partition 64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0 broker=0] No checkpointed highwatermark is found for partition 64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0 (kafka.cluster.Partition)
[2019-08-14 09:06:20,288] INFO Replica loaded for partition 64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:06:20,289] INFO [Partition 64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0 broker=0] 64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:06:20,294] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:06:20,300] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:06:20,302] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-08-14 09:06:20,303] INFO Created log for partition 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:06:20,307] INFO [Partition 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 broker=0] No checkpointed highwatermark is found for partition 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 (kafka.cluster.Partition)
[2019-08-14 09:06:20,308] INFO Replica loaded for partition 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:06:20,308] INFO [Partition 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 broker=0] 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:06:20,335] INFO [GroupCoordinator 0]: Assignment received from leader for group 64907477-1a30-44ca-aba9-921bdb9571ca for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:07:20,486] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Incrementing log start offset to 3 (kafka.log.Log)
[2019-08-14 09:08:24,359] INFO [GroupCoordinator 0]: Member 64907477-1a30-44ca-aba9-921bdb9571ca-421193fa-8707-4adc-babd-4bbda809fd3c-StreamThread-1-consumer-734749e1-9e14-4122-b300-b247d94d9cb3 in group 64907477-1a30-44ca-aba9-921bdb9571ca has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:08:24,360] INFO [GroupCoordinator 0]: Preparing to rebalance group 64907477-1a30-44ca-aba9-921bdb9571ca in state PreparingRebalance with old generation 1 (__consumer_offsets-20) (reason: removing member 64907477-1a30-44ca-aba9-921bdb9571ca-421193fa-8707-4adc-babd-4bbda809fd3c-StreamThread-1-consumer-734749e1-9e14-4122-b300-b247d94d9cb3 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:08:24,362] INFO [GroupCoordinator 0]: Group 64907477-1a30-44ca-aba9-921bdb9571ca with generation 2 is now empty (__consumer_offsets-20) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:10:26,717] INFO [GroupCoordinator 0]: Preparing to rebalance group 1da6ba26-32f5-4751-8939-0f7a3954df45 in state PreparingRebalance with old generation 0 (__consumer_offsets-27) (reason: Adding new member 1da6ba26-32f5-4751-8939-0f7a3954df45-81be067e-0c7a-4b4c-a90a-ec54a14b6333-StreamThread-1-consumer-1a5c3dd0-0e3b-4ab4-9459-397f8daa65e4 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:10:26,723] INFO [GroupCoordinator 0]: Stabilized group 1da6ba26-32f5-4751-8939-0f7a3954df45 generation 1 (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:10:26,803] INFO Creating topic 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition with configuration {cleanup.policy=delete, segment.bytes=52428800, retention.ms=-1} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:10:26,806] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x13b zxid:0x1c7 txntype:-1 reqpath:n/a Error Path:/config/topics/1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition Error:KeeperErrorCode = NoNode for /config/topics/1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:10:26,828] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:10:26,855] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:10:26,857] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 09:10:26,858] INFO Created log for partition 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, retention.ms -> -1, segment.bytes -> 52428800, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:10:26,862] INFO [Partition 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 broker=0] No checkpointed highwatermark is found for partition 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 (kafka.cluster.Partition)
[2019-08-14 09:10:26,863] INFO Replica loaded for partition 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:10:26,864] INFO [Partition 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 broker=0] 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:10:26,876] INFO Creating topic 1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:10:26,878] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x145 zxid:0x1cd txntype:-1 reqpath:n/a Error Path:/config/topics/1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog Error:KeeperErrorCode = NoNode for /config/topics/1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:10:26,885] INFO Creating topic 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:10:26,886] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x14b zxid:0x1d0 txntype:-1 reqpath:n/a Error Path:/config/topics/1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog Error:KeeperErrorCode = NoNode for /config/topics/1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:10:26,897] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:10:26,903] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:10:26,905] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-08-14 09:10:26,906] INFO Created log for partition 1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:10:26,910] INFO [Partition 1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0 broker=0] No checkpointed highwatermark is found for partition 1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0 (kafka.cluster.Partition)
[2019-08-14 09:10:26,911] INFO Replica loaded for partition 1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:10:26,912] INFO [Partition 1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0 broker=0] 1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:10:26,917] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:10:26,923] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:10:26,925] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-08-14 09:10:26,926] INFO Created log for partition 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:10:26,929] INFO [Partition 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 broker=0] No checkpointed highwatermark is found for partition 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 (kafka.cluster.Partition)
[2019-08-14 09:10:26,930] INFO Replica loaded for partition 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:10:26,931] INFO [Partition 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 broker=0] 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:10:26,949] INFO [GroupCoordinator 0]: Assignment received from leader for group 1da6ba26-32f5-4751-8939-0f7a3954df45 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:11:27,157] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Incrementing log start offset to 3 (kafka.log.Log)
[2019-08-14 09:13:54,145] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 09:16:58,006] INFO [GroupCoordinator 0]: Member 1da6ba26-32f5-4751-8939-0f7a3954df45-81be067e-0c7a-4b4c-a90a-ec54a14b6333-StreamThread-1-consumer-1a5c3dd0-0e3b-4ab4-9459-397f8daa65e4 in group 1da6ba26-32f5-4751-8939-0f7a3954df45 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:16:58,007] INFO [GroupCoordinator 0]: Preparing to rebalance group 1da6ba26-32f5-4751-8939-0f7a3954df45 in state PreparingRebalance with old generation 1 (__consumer_offsets-27) (reason: removing member 1da6ba26-32f5-4751-8939-0f7a3954df45-81be067e-0c7a-4b4c-a90a-ec54a14b6333-StreamThread-1-consumer-1a5c3dd0-0e3b-4ab4-9459-397f8daa65e4 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:16:58,009] INFO [GroupCoordinator 0]: Group 1da6ba26-32f5-4751-8939-0f7a3954df45 with generation 2 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:17:03,095] INFO [GroupCoordinator 0]: Preparing to rebalance group 31b72962-71d9-4880-b24d-2c40810955a6 in state PreparingRebalance with old generation 0 (__consumer_offsets-13) (reason: Adding new member 31b72962-71d9-4880-b24d-2c40810955a6-09e350e2-6bb3-43a0-8642-b53181c9d7c3-StreamThread-1-consumer-1cea252a-d1f1-4b30-8153-a8634259eea5 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:17:03,129] INFO [GroupCoordinator 0]: Stabilized group 31b72962-71d9-4880-b24d-2c40810955a6 generation 1 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:17:03,159] INFO Creating topic 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition with configuration {cleanup.policy=delete, segment.bytes=52428800, retention.ms=-1} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:17:03,162] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x159 zxid:0x1d9 txntype:-1 reqpath:n/a Error Path:/config/topics/31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition Error:KeeperErrorCode = NoNode for /config/topics/31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:17:03,189] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:17:03,205] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:17:03,215] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-08-14 09:17:03,217] INFO Created log for partition 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, retention.ms -> -1, segment.bytes -> 52428800, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:17:03,221] INFO [Partition 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 broker=0] No checkpointed highwatermark is found for partition 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 (kafka.cluster.Partition)
[2019-08-14 09:17:03,222] INFO Replica loaded for partition 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:17:03,223] INFO [Partition 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 broker=0] 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:17:03,237] INFO Creating topic 31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:17:03,239] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x163 zxid:0x1df txntype:-1 reqpath:n/a Error Path:/config/topics/31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog Error:KeeperErrorCode = NoNode for /config/topics/31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:17:03,246] INFO Creating topic 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:17:03,247] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x169 zxid:0x1e2 txntype:-1 reqpath:n/a Error Path:/config/topics/31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog Error:KeeperErrorCode = NoNode for /config/topics/31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:17:03,256] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:17:03,262] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:17:03,264] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-08-14 09:17:03,266] INFO Created log for partition 31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:17:03,292] INFO [Partition 31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0 broker=0] No checkpointed highwatermark is found for partition 31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0 (kafka.cluster.Partition)
[2019-08-14 09:17:03,294] INFO Replica loaded for partition 31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:17:03,295] INFO [Partition 31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0 broker=0] 31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:17:03,306] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:17:03,313] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:17:03,316] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:17:03,318] INFO Created log for partition 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:17:03,322] INFO [Partition 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 broker=0] No checkpointed highwatermark is found for partition 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 (kafka.cluster.Partition)
[2019-08-14 09:17:03,323] INFO Replica loaded for partition 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:17:03,324] INFO [Partition 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 broker=0] 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:17:03,346] INFO [GroupCoordinator 0]: Assignment received from leader for group 31b72962-71d9-4880-b24d-2c40810955a6 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:18:03,613] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Incrementing log start offset to 3 (kafka.log.Log)
[2019-08-14 09:23:54,164] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 09:24:07,399] INFO [GroupCoordinator 0]: Member 31b72962-71d9-4880-b24d-2c40810955a6-09e350e2-6bb3-43a0-8642-b53181c9d7c3-StreamThread-1-consumer-1cea252a-d1f1-4b30-8153-a8634259eea5 in group 31b72962-71d9-4880-b24d-2c40810955a6 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:24:07,400] INFO [GroupCoordinator 0]: Preparing to rebalance group 31b72962-71d9-4880-b24d-2c40810955a6 in state PreparingRebalance with old generation 1 (__consumer_offsets-13) (reason: removing member 31b72962-71d9-4880-b24d-2c40810955a6-09e350e2-6bb3-43a0-8642-b53181c9d7c3-StreamThread-1-consumer-1cea252a-d1f1-4b30-8153-a8634259eea5 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:24:07,402] INFO [GroupCoordinator 0]: Group 31b72962-71d9-4880-b24d-2c40810955a6 with generation 2 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:24:32,540] INFO [GroupCoordinator 0]: Preparing to rebalance group 32e7965d-8736-4377-a894-348ae45606a1 in state PreparingRebalance with old generation 0 (__consumer_offsets-36) (reason: Adding new member 32e7965d-8736-4377-a894-348ae45606a1-d9585bdb-bb0e-47df-99c9-87269ab133ee-StreamThread-1-consumer-b8762424-b5e2-4db9-b6d3-d532e58161d3 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:24:32,551] INFO [GroupCoordinator 0]: Stabilized group 32e7965d-8736-4377-a894-348ae45606a1 generation 1 (__consumer_offsets-36) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:24:32,567] INFO Creating topic 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition with configuration {cleanup.policy=delete, segment.bytes=52428800, retention.ms=-1} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:24:32,569] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x177 zxid:0x1eb txntype:-1 reqpath:n/a Error Path:/config/topics/32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition Error:KeeperErrorCode = NoNode for /config/topics/32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:24:32,586] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:24:32,591] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:24:32,593] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-08-14 09:24:32,594] INFO Created log for partition 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, retention.ms -> -1, segment.bytes -> 52428800, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:24:32,598] INFO [Partition 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 broker=0] No checkpointed highwatermark is found for partition 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 (kafka.cluster.Partition)
[2019-08-14 09:24:32,599] INFO Replica loaded for partition 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:24:32,600] INFO [Partition 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 broker=0] 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:24:32,625] INFO Creating topic 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:24:32,631] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x181 zxid:0x1f1 txntype:-1 reqpath:n/a Error Path:/config/topics/32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog Error:KeeperErrorCode = NoNode for /config/topics/32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:24:32,645] INFO Creating topic 32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:24:32,647] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x188 zxid:0x1f5 txntype:-1 reqpath:n/a Error Path:/config/topics/32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog Error:KeeperErrorCode = NoNode for /config/topics/32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:24:32,654] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:24:32,661] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:24:32,663] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 09:24:32,666] INFO Created log for partition 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:24:32,670] INFO [Partition 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 broker=0] No checkpointed highwatermark is found for partition 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 (kafka.cluster.Partition)
[2019-08-14 09:24:32,672] INFO Replica loaded for partition 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:24:32,674] INFO [Partition 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 broker=0] 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:24:32,682] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:24:32,687] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:24:32,689] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-08-14 09:24:32,690] INFO Created log for partition 32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:24:32,694] INFO [Partition 32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0 broker=0] No checkpointed highwatermark is found for partition 32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0 (kafka.cluster.Partition)
[2019-08-14 09:24:32,695] INFO Replica loaded for partition 32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:24:32,696] INFO [Partition 32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0 broker=0] 32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:24:32,715] INFO [GroupCoordinator 0]: Assignment received from leader for group 32e7965d-8736-4377-a894-348ae45606a1 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:25:32,819] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Incrementing log start offset to 3 (kafka.log.Log)
[2019-08-14 09:27:54,789] INFO [GroupCoordinator 0]: Member 32e7965d-8736-4377-a894-348ae45606a1-d9585bdb-bb0e-47df-99c9-87269ab133ee-StreamThread-1-consumer-b8762424-b5e2-4db9-b6d3-d532e58161d3 in group 32e7965d-8736-4377-a894-348ae45606a1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:27:54,790] INFO [GroupCoordinator 0]: Preparing to rebalance group 32e7965d-8736-4377-a894-348ae45606a1 in state PreparingRebalance with old generation 1 (__consumer_offsets-36) (reason: removing member 32e7965d-8736-4377-a894-348ae45606a1-d9585bdb-bb0e-47df-99c9-87269ab133ee-StreamThread-1-consumer-b8762424-b5e2-4db9-b6d3-d532e58161d3 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:27:54,792] INFO [GroupCoordinator 0]: Group 32e7965d-8736-4377-a894-348ae45606a1 with generation 2 is now empty (__consumer_offsets-36) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:27:58,975] INFO [GroupCoordinator 0]: Preparing to rebalance group d92994d3-4f79-4b40-aa5c-cde2e87251d9 in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member d92994d3-4f79-4b40-aa5c-cde2e87251d9-9eb18da6-2aa7-4288-96a9-500276365068-StreamThread-1-consumer-c76c0030-7504-4e03-9e4f-2b4617f25280 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:27:58,990] INFO [GroupCoordinator 0]: Stabilized group d92994d3-4f79-4b40-aa5c-cde2e87251d9 generation 1 (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:27:59,080] INFO Creating topic d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition with configuration {cleanup.policy=delete, segment.bytes=52428800, retention.ms=-1} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:27:59,089] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x195 zxid:0x1fd txntype:-1 reqpath:n/a Error Path:/config/topics/d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition Error:KeeperErrorCode = NoNode for /config/topics/d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:27:59,125] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:27:59,129] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:27:59,131] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-08-14 09:27:59,133] INFO Created log for partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, retention.ms -> -1, segment.bytes -> 52428800, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:27:59,136] INFO [Partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0 broker=0] No checkpointed highwatermark is found for partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0 (kafka.cluster.Partition)
[2019-08-14 09:27:59,139] INFO Replica loaded for partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:27:59,139] INFO [Partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0 broker=0] d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:27:59,151] INFO Creating topic d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:27:59,153] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x19f zxid:0x203 txntype:-1 reqpath:n/a Error Path:/config/topics/d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog Error:KeeperErrorCode = NoNode for /config/topics/d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:27:59,160] INFO Creating topic d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:27:59,161] INFO Got user-level KeeperException when processing sessionid:0x10014e807610000 type:setData cxid:0x1a6 zxid:0x207 txntype:-1 reqpath:n/a Error Path:/config/topics/d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog Error:KeeperErrorCode = NoNode for /config/topics/d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:27:59,168] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:27:59,174] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:27:59,176] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-08-14 09:27:59,177] INFO Created log for partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:27:59,181] INFO [Partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0 broker=0] No checkpointed highwatermark is found for partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0 (kafka.cluster.Partition)
[2019-08-14 09:27:59,182] INFO Replica loaded for partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:27:59,182] INFO [Partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0 broker=0] d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:27:59,188] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:27:59,195] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:27:59,197] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 09:27:59,198] INFO Created log for partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:27:59,202] INFO [Partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0 broker=0] No checkpointed highwatermark is found for partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0 (kafka.cluster.Partition)
[2019-08-14 09:27:59,203] INFO Replica loaded for partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:27:59,204] INFO [Partition d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0 broker=0] d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:27:59,226] INFO [GroupCoordinator 0]: Assignment received from leader for group d92994d3-4f79-4b40-aa5c-cde2e87251d9 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:28:59,374] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Incrementing log start offset to 3 (kafka.log.Log)
[2019-08-14 09:30:32,934] INFO [GroupCoordinator 0]: Member consumer-1-44f5adf0-a022-4d24-8c95-0348c9e3243e in group console-consumer-59275 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:30:32,935] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-59275 in state PreparingRebalance with old generation 1 (__consumer_offsets-9) (reason: removing member consumer-1-44f5adf0-a022-4d24-8c95-0348c9e3243e on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:30:32,937] INFO [GroupCoordinator 0]: Group console-consumer-59275 with generation 2 is now empty (__consumer_offsets-9) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:33:54,167] INFO [GroupMetadataManager brokerId=0] Group console-consumer-59275 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 09:33:54,170] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 09:34:14,505] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-58149 in state PreparingRebalance with old generation 0 (__consumer_offsets-18) (reason: Adding new member consumer-1-da68f17c-a615-45bd-9683-c668a43e582b with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:34:14,507] INFO [GroupCoordinator 0]: Stabilized group console-consumer-58149 generation 1 (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:34:14,516] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-58149 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:34:14,525] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Rolled new log segment at offset 11 in 4 ms. (kafka.log.Log)
[2019-08-14 09:34:24,691] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2016)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2016)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2016)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-08-14 09:34:24,706] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-08-14 09:34:24,708] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, cwct-stream-input-test-1-0, cwct-producer-test-4-0, __consumer_offsets-30, cwct-producer-test-1-0, 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, 64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, __consumer_offsets-9, 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, __consumer_offsets-46, cwct-stream-output-test-1-0, 32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, __consumer_offsets-25, __consumer_offsets-35, cwct-stream-1-0, __consumer_offsets-41, d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, test-http-producer-0, __consumer_offsets-31, __consumer_offsets-36, cwct-producer-test-5-0, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, cwct-producer-test-2-0, dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, __consumer_offsets-15, __consumer_offsets-24, cwct-stream-test-1-0, d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, 476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, 476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, 1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, 40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, 476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, key-based-events-1-0, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, 31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, cwct-producer-test-3-0, __consumer_offsets-32, __consumer_offsets-40, 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, 79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:34:24,719] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, cwct-stream-input-test-1-0, cwct-producer-test-4-0, __consumer_offsets-30, cwct-producer-test-1-0, 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, 64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, __consumer_offsets-9, 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, __consumer_offsets-46, cwct-stream-output-test-1-0, 32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, __consumer_offsets-25, __consumer_offsets-35, cwct-stream-1-0, __consumer_offsets-41, d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, 1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, 31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, test-http-producer-0, __consumer_offsets-31, __consumer_offsets-36, cwct-producer-test-5-0, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, cwct-producer-test-2-0, dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, __consumer_offsets-15, __consumer_offsets-24, cwct-stream-test-1-0, d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, 476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, 476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, 1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, 40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, 64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, 476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, key-based-events-1-0, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, 31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, cwct-producer-test-3-0, __consumer_offsets-32, __consumer_offsets-40, 32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, 79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-14 09:34:24,761] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-22,cwct-stream-input-test-1-0,cwct-producer-test-4-0,__consumer_offsets-30,cwct-producer-test-1-0,1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0,__consumer_offsets-9,31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0,d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0,__consumer_offsets-46,cwct-stream-output-test-1-0,32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0,__consumer_offsets-25,__consumer_offsets-35,cwct-stream-1-0,__consumer_offsets-41,d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0,31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,test-http-producer-0,__consumer_offsets-31,__consumer_offsets-36,cwct-producer-test-5-0,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,cwct-producer-test-2-0,dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0,__consumer_offsets-15,__consumer_offsets-24,cwct-stream-test-1-0,d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0,476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0,32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0,64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0,40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0,f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0,64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0,476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,key-based-events-1-0,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,cwct-producer-test-3-0,__consumer_offsets-32,__consumer_offsets-40,32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0,79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0 and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-08-14 09:34:24,771] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-08-14 09:34:24,782] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:270)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1180)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-08-14 09:34:24,783] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-08-14 09:34:25,126] WARN Exception causing close of session 0x10014e807610000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-14 09:34:25,129] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:61783 which had sessionid 0x10014e807610000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-14 09:34:29,870] INFO Expiring session 0x10014e807610000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:34:29,871] INFO Processed session termination for sessionid: 0x10014e807610000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:16,469] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-14 09:35:17,024] INFO starting (kafka.server.KafkaServer)
[2019-08-14 09:35:17,025] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-14 09:35:17,060] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:35:17,067] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,067] INFO Client environment:host.name=SAKSHAMA2012.pacific.costcotravel.com (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,067] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,068] INFO Client environment:java.vendor=AdoptOpenJDK (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,068] INFO Client environment:java.home=D:\java\jdk (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,068] INFO Client environment:java.class.path=..;D:\kafka_2.12-2.3.0\libs\activation-1.1.1.jar;D:\kafka_2.12-2.3.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\argparse4j-0.7.0.jar;D:\kafka_2.12-2.3.0\libs\audience-annotations-0.5.0.jar;D:\kafka_2.12-2.3.0\libs\commons-lang3-3.8.1.jar;D:\kafka_2.12-2.3.0\libs\connect-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-basic-auth-extension-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-file-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-json-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-runtime-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-transforms-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\guava-20.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-api-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-locator-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-utils-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jackson-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-core-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-databind-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-dataformat-csv-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-datatype-jdk8-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-base-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-json-provider-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-jaxb-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-paranamer-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-scala_2.12-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka_2.12-2.3.0\libs\jakarta.inject-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka_2.12-2.3.0\libs\javassist-3.22.0-CR2.jar;D:\kafka_2.12-2.3.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka_2.12-2.3.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka_2.12-2.3.0\libs\jaxb-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\jersey-client-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-common-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-hk2-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-server-2.28.jar;D:\kafka_2.12-2.3.0\libs\jetty-client-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-continuation-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-http-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-io-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-security-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-server-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlet-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlets-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-util-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jopt-simple-5.0.4.jar;D:\kafka_2.12-2.3.0\libs\jsr305-3.0.2.jar;D:\kafka_2.12-2.3.0\libs\kafka-clients-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-log4j-appender-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-examples-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-scala_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-test-utils-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-tools-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar.asc;D:\kafka_2.12-2.3.0\libs\log4j-1.2.17.jar;D:\kafka_2.12-2.3.0\libs\lz4-java-1.6.0.jar;D:\kafka_2.12-2.3.0\libs\maven-artifact-3.6.1.jar;D:\kafka_2.12-2.3.0\libs\metrics-core-2.2.0.jar;D:\kafka_2.12-2.3.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka_2.12-2.3.0\libs\paranamer-2.8.jar;D:\kafka_2.12-2.3.0\libs\plexus-utils-3.2.0.jar;D:\kafka_2.12-2.3.0\libs\reflections-0.9.11.jar;D:\kafka_2.12-2.3.0\libs\rocksdbjni-5.18.3.jar;D:\kafka_2.12-2.3.0\libs\scala-library-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\scala-logging_2.12-3.9.0.jar;D:\kafka_2.12-2.3.0\libs\scala-reflect-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\slf4j-api-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\slf4j-log4j12-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\snappy-java-1.1.7.3.jar;D:\kafka_2.12-2.3.0\libs\spotbugs-annotations-3.1.9.jar;D:\kafka_2.12-2.3.0\libs\validation-api-2.0.1.Final.jar;D:\kafka_2.12-2.3.0\libs\zkclient-0.11.jar;D:\kafka_2.12-2.3.0\libs\zookeeper-3.4.14.jar;D:\kafka_2.12-2.3.0\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,083] INFO Client environment:java.library.path=D:\java\jdk\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\Java\jdk1.8.0_73\bin;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;D:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\ManagementStudio\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;D:\confluent-5.2.2\bin;D:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\saksham.aggarwal\AppData\Local\atom\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,086] INFO Client environment:java.io.tmpdir=C:\Users\SAKSHA~1.AGG\AppData\Local\Temp\2\ (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,087] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,088] INFO Client environment:os.name=Windows Server 2012 R2 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,089] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,090] INFO Client environment:os.version=6.3 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,091] INFO Client environment:user.name=saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,091] INFO Client environment:user.home=C:\Users\saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,092] INFO Client environment:user.dir=D:\kafka_2.12-2.3.0\bin\windows (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,094] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@648c94da (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:35:17,116] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:35:17,120] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:35:17,124] INFO Accepted socket connection from /127.0.0.1:64101 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-14 09:35:17,124] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:35:17,128] INFO Client attempting to establish new session at /127.0.0.1:64101 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:35:17,130] INFO Established session 0x10014e807610001 with negotiated timeout 6000 for client /127.0.0.1:64101 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:35:17,132] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10014e807610001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:35:17,136] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:35:17,171] INFO Got user-level KeeperException when processing sessionid:0x10014e807610001 type:create cxid:0x1 zxid:0x211 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:17,184] INFO Got user-level KeeperException when processing sessionid:0x10014e807610001 type:create cxid:0x2 zxid:0x212 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:17,187] INFO Got user-level KeeperException when processing sessionid:0x10014e807610001 type:create cxid:0x3 zxid:0x213 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:17,190] INFO Got user-level KeeperException when processing sessionid:0x10014e807610001 type:create cxid:0x4 zxid:0x214 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:17,197] INFO Got user-level KeeperException when processing sessionid:0x10014e807610001 type:create cxid:0x5 zxid:0x215 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:17,200] INFO Got user-level KeeperException when processing sessionid:0x10014e807610001 type:create cxid:0x6 zxid:0x216 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:17,202] INFO Got user-level KeeperException when processing sessionid:0x10014e807610001 type:create cxid:0x7 zxid:0x217 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:17,205] INFO Got user-level KeeperException when processing sessionid:0x10014e807610001 type:create cxid:0x8 zxid:0x218 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:17,208] INFO Got user-level KeeperException when processing sessionid:0x10014e807610001 type:create cxid:0x9 zxid:0x219 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:17,210] INFO Got user-level KeeperException when processing sessionid:0x10014e807610001 type:create cxid:0xa zxid:0x21a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:17,213] INFO Got user-level KeeperException when processing sessionid:0x10014e807610001 type:create cxid:0xb zxid:0x21b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:17,216] INFO Got user-level KeeperException when processing sessionid:0x10014e807610001 type:create cxid:0xc zxid:0x21c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:17,218] INFO Got user-level KeeperException when processing sessionid:0x10014e807610001 type:create cxid:0xd zxid:0x21d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:35:17,375] INFO Cluster ID = Bx_HGZA6SbGgI2xxf7icgw (kafka.server.KafkaServer)
[2019-08-14 09:35:17,443] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 09:35:17,499] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 09:35:17,563] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:35:17,564] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:35:17,563] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:35:17,631] INFO Loading logs. (kafka.log.LogManager)
[2019-08-14 09:35:17,692] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:17,695] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,745] INFO [ProducerStateManager partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,765] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,769] INFO [ProducerStateManager partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,781] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 115 ms (kafka.log.Log)
[2019-08-14 09:35:17,796] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:17,797] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,801] INFO [ProducerStateManager partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,806] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,807] INFO [ProducerStateManager partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,809] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-08-14 09:35:17,815] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:17,816] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,826] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,828] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:35:17,833] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:17,834] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,838] INFO [ProducerStateManager partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,845] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,847] INFO [ProducerStateManager partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,849] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 18 ms (kafka.log.Log)
[2019-08-14 09:35:17,855] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:17,856] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,860] INFO [ProducerStateManager partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,864] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,866] INFO [ProducerStateManager partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,868] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-08-14 09:35:17,874] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:17,874] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,885] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,898] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 26 ms (kafka.log.Log)
[2019-08-14 09:35:17,904] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:17,905] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,909] INFO [ProducerStateManager partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,915] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,917] INFO [ProducerStateManager partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,919] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 17 ms (kafka.log.Log)
[2019-08-14 09:35:17,925] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:17,926] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,930] INFO [ProducerStateManager partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,937] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,939] INFO [ProducerStateManager partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,940] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 17 ms (kafka.log.Log)
[2019-08-14 09:35:17,946] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:17,947] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,954] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,956] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-08-14 09:35:17,961] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:17,962] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,966] INFO [ProducerStateManager partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,970] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,972] INFO [ProducerStateManager partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,974] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:35:17,979] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:17,980] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,984] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,992] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:17,994] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:17,996] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 19 ms (kafka.log.Log)
[2019-08-14 09:35:18,001] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,002] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,006] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,011] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,022] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,023] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 24 ms (kafka.log.Log)
[2019-08-14 09:35:18,029] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,030] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,037] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,039] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 4 and log end offset 4 in 12 ms (kafka.log.Log)
[2019-08-14 09:35:18,045] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,046] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,050] INFO [ProducerStateManager partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,055] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,056] INFO [ProducerStateManager partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,058] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-08-14 09:35:18,063] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,064] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,068] INFO [ProducerStateManager partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,072] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,074] INFO [ProducerStateManager partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,076] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:35:18,081] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,082] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,089] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,090] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,095] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,096] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,099] INFO [ProducerStateManager partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,104] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,106] INFO [ProducerStateManager partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,107] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 14 ms (kafka.log.Log)
[2019-08-14 09:35:18,112] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,113] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,117] INFO [ProducerStateManager partition=cwct-producer-test-1-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,121] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,123] INFO [ProducerStateManager partition=cwct-producer-test-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-1-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,124] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 14 ms (kafka.log.Log)
[2019-08-14 09:35:18,128] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,129] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,138] INFO [ProducerStateManager partition=cwct-producer-test-2-0] Writing producer snapshot at offset 34 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,143] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 34 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,145] INFO [ProducerStateManager partition=cwct-producer-test-2-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-2-0\00000000000000000034.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,146] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 34 in 20 ms (kafka.log.Log)
[2019-08-14 09:35:18,150] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,151] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,155] INFO [ProducerStateManager partition=cwct-producer-test-3-0] Writing producer snapshot at offset 33 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,160] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 33 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,161] INFO [ProducerStateManager partition=cwct-producer-test-3-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-3-0\00000000000000000033.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,162] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 33 in 14 ms (kafka.log.Log)
[2019-08-14 09:35:18,167] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,167] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,172] INFO [ProducerStateManager partition=cwct-producer-test-4-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,176] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,178] INFO [ProducerStateManager partition=cwct-producer-test-4-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-4-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,179] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 14 ms (kafka.log.Log)
[2019-08-14 09:35:18,183] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,183] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,187] INFO [ProducerStateManager partition=cwct-producer-test-5-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,191] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,193] INFO [ProducerStateManager partition=cwct-producer-test-5-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-5-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,194] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,198] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,198] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,204] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,206] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-08-14 09:35:18,209] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,210] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,213] INFO [ProducerStateManager partition=cwct-stream-input-test-1-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,218] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,219] INFO [ProducerStateManager partition=cwct-stream-input-test-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-stream-input-test-1-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,220] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 12 ms (kafka.log.Log)
[2019-08-14 09:35:18,225] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,225] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,232] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,234] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,238] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,238] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,242] INFO [ProducerStateManager partition=cwct-stream-test-1-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,246] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,248] INFO [ProducerStateManager partition=cwct-stream-test-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-stream-test-1-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,249] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,252] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,253] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,257] INFO [ProducerStateManager partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,261] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,263] INFO [ProducerStateManager partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,264] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,268] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,269] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,273] INFO [ProducerStateManager partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,277] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,279] INFO [ProducerStateManager partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,281] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 14 ms (kafka.log.Log)
[2019-08-14 09:35:18,285] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,286] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,292] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,294] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,299] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,300] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,303] INFO [ProducerStateManager partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,308] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,309] INFO [ProducerStateManager partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,311] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 14 ms (kafka.log.Log)
[2019-08-14 09:35:18,315] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,316] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,320] INFO [ProducerStateManager partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,324] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,325] INFO [ProducerStateManager partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,327] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 14 ms (kafka.log.Log)
[2019-08-14 09:35:18,331] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,332] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,335] INFO [ProducerStateManager partition=key-based-events-1-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,340] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,342] INFO [ProducerStateManager partition=key-based-events-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\key-based-events-1-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,343] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,347] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,348] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,351] INFO [ProducerStateManager partition=test-http-producer-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,355] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,357] INFO [ProducerStateManager partition=test-http-producer-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\test-http-producer-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,358] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,362] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,362] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,366] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,369] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,371] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,372] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:35:18,375] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,376] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,379] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,385] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,387] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,388] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 14 ms (kafka.log.Log)
[2019-08-14 09:35:18,391] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,392] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,395] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,399] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,401] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-10\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,402] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:35:18,405] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,406] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,409] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,414] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,416] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,417] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 12 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,421] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,421] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,427] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,428] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-08-14 09:35:18,432] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,432] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,435] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,439] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,441] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,442] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 12 ms (kafka.log.Log)
[2019-08-14 09:35:18,445] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,446] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,449] INFO [ProducerStateManager partition=__consumer_offsets-14] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,454] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,455] INFO [ProducerStateManager partition=__consumer_offsets-14] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-14\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,456] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:35:18,460] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,460] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,464] INFO [ProducerStateManager partition=__consumer_offsets-15] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,468] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,470] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-15\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,471] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,474] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,475] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,479] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,483] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,484] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,485] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,488] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,489] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,493] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,497] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,499] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,500] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,503] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-08-14 09:35:18,504] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.index (kafka.log.Log)
[2019-08-14 09:35:18,506] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-08-14 09:35:18,507] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.log (kafka.log.Log)
[2019-08-14 09:35:18,509] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.log (kafka.log.Log)
[2019-08-14 09:35:18,512] ERROR [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Could not find offset index file corresponding to log file D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-14 09:35:18,513] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,518] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,519] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 11 (kafka.log.Log)
[2019-08-14 09:35:18,520] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,532] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,534] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,539] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,541] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,542] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 12 in 40 ms (kafka.log.Log)
[2019-08-14 09:35:18,546] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,547] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,550] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,554] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,555] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,556] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-08-14 09:35:18,559] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,560] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,565] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,567] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-08-14 09:35:18,570] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,571] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,574] INFO [ProducerStateManager partition=__consumer_offsets-20] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,579] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,580] INFO [ProducerStateManager partition=__consumer_offsets-20] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-20\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,581] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 12 ms (kafka.log.Log)
[2019-08-14 09:35:18,584] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,585] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,588] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,596] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,597] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,599] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 16 ms (kafka.log.Log)
[2019-08-14 09:35:18,602] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,603] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,608] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,610] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-08-14 09:35:18,613] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,613] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,617] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,622] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,623] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,624] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,627] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,628] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,631] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,643] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,645] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,646] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 20 ms (kafka.log.Log)
[2019-08-14 09:35:18,649] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,649] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,655] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,656] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-08-14 09:35:18,659] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,660] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,663] INFO [ProducerStateManager partition=__consumer_offsets-26] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,667] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,668] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-26\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,670] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:35:18,673] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,673] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,677] INFO [ProducerStateManager partition=__consumer_offsets-27] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,682] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 20 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,683] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-27\00000000000000000020.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,684] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 20 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,687] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,688] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,691] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,695] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,696] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,697] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,700] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,701] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,706] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,707] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-08-14 09:35:18,710] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,711] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,714] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,718] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,719] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,720] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,723] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,724] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,727] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,731] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,732] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,733] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,736] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,737] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,740] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,744] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,745] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,746] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,749] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,750] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,755] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,756] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-08-14 09:35:18,759] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,760] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,763] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,767] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,768] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-33\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,769] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,772] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,772] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,776] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,780] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,781] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,782] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,785] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,786] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,789] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,793] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,795] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-35\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,795] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,799] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,799] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,803] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,821] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,822] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,823] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 26 ms (kafka.log.Log)
[2019-08-14 09:35:18,827] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,827] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,831] INFO [ProducerStateManager partition=__consumer_offsets-37] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,836] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,838] INFO [ProducerStateManager partition=__consumer_offsets-37] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-37\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,839] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 14 ms (kafka.log.Log)
[2019-08-14 09:35:18,842] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,843] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,846] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,851] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,852] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-38\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,853] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,856] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,857] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,860] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,864] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,865] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,866] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,869] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,873] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,879] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,880] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-08-14 09:35:18,884] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,884] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,890] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,891] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-08-14 09:35:18,894] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,895] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,898] INFO [ProducerStateManager partition=__consumer_offsets-41] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,902] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,903] INFO [ProducerStateManager partition=__consumer_offsets-41] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-41\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,904] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,908] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,908] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,912] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 19 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,916] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 19 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,918] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000019.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,919] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 19 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,922] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,922] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,925] INFO [ProducerStateManager partition=__consumer_offsets-43] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,929] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,931] INFO [ProducerStateManager partition=__consumer_offsets-43] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-43\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,932] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:35:18,934] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,935] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,940] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,941] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-08-14 09:35:18,944] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,945] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,948] INFO [ProducerStateManager partition=__consumer_offsets-45] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,952] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,953] INFO [ProducerStateManager partition=__consumer_offsets-45] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-45\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,954] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,957] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,957] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,960] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,964] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,965] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,966] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,969] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,970] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,973] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,978] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,980] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,981] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:18,983] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,984] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,987] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,990] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,992] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-48\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:18,993] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:18,995] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:18,996] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:18,999] INFO [ProducerStateManager partition=__consumer_offsets-49] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:19,003] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:19,005] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:19,006] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:35:19,008] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:19,009] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:19,012] INFO [ProducerStateManager partition=__consumer_offsets-5] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:19,016] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:19,017] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:19,018] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:19,021] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:19,022] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:19,024] INFO [ProducerStateManager partition=__consumer_offsets-6] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:19,028] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:19,029] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-6\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:19,030] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 10 ms (kafka.log.Log)
[2019-08-14 09:35:19,033] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:19,034] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:19,037] INFO [ProducerStateManager partition=__consumer_offsets-7] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:19,041] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:19,043] INFO [ProducerStateManager partition=__consumer_offsets-7] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-7\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:19,043] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:35:19,055] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:19,056] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:19,059] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:19,063] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:19,064] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-8\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:19,065] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 20 ms (kafka.log.Log)
[2019-08-14 09:35:19,068] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:35:19,069] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:19,072] INFO [ProducerStateManager partition=__consumer_offsets-9] Writing producer snapshot at offset 14 (kafka.log.ProducerStateManager)
[2019-08-14 09:35:19,078] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 14 with message format version 2 (kafka.log.Log)
[2019-08-14 09:35:19,079] INFO [ProducerStateManager partition=__consumer_offsets-9] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000014.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:35:19,080] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 14 in 13 ms (kafka.log.Log)
[2019-08-14 09:35:19,083] INFO Logs loading complete in 1451 ms. (kafka.log.LogManager)
[2019-08-14 09:35:19,096] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-14 09:35:19,097] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-14 09:35:19,352] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2016)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2016)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2016)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-08-14 09:35:19,440] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-14 09:35:19,469] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:270)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1180)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-08-14 09:35:19,509] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:270)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1180)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-08-14 09:35:19,510] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-08-14 09:35:19,521] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-08-14 09:35:19,556] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:270)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1180)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-08-14 09:35:19,606] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:35:19,610] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:35:19,606] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:35:19,614] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:35:19,621] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-14 09:35:19,622] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2016)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2016)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2016)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-08-14 09:35:19,631] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-08-14 09:35:19,649] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-08-14 09:35:19,650] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-08-14 09:35:19,654] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-08-14 09:35:19,996] WARN Exception causing close of session 0x10014e807610001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-14 09:35:19,997] INFO Closed socket connection for client /127.0.0.1:64101 which had sessionid 0x10014e807610001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-14 09:35:26,870] INFO Expiring session 0x10014e807610001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:35:26,870] INFO Processed session termination for sessionid: 0x10014e807610001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,045] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-14 09:36:18,603] INFO starting (kafka.server.KafkaServer)
[2019-08-14 09:36:18,604] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-14 09:36:18,641] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:36:18,648] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,648] INFO Client environment:host.name=SAKSHAMA2012.pacific.costcotravel.com (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,648] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,649] INFO Client environment:java.vendor=AdoptOpenJDK (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,649] INFO Client environment:java.home=D:\java\jdk (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,649] INFO Client environment:java.class.path=..;D:\kafka_2.12-2.3.0\libs\activation-1.1.1.jar;D:\kafka_2.12-2.3.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\argparse4j-0.7.0.jar;D:\kafka_2.12-2.3.0\libs\audience-annotations-0.5.0.jar;D:\kafka_2.12-2.3.0\libs\commons-lang3-3.8.1.jar;D:\kafka_2.12-2.3.0\libs\connect-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-basic-auth-extension-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-file-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-json-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-runtime-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-transforms-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\guava-20.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-api-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-locator-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-utils-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jackson-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-core-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-databind-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-dataformat-csv-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-datatype-jdk8-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-base-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-json-provider-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-jaxb-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-paranamer-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-scala_2.12-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka_2.12-2.3.0\libs\jakarta.inject-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka_2.12-2.3.0\libs\javassist-3.22.0-CR2.jar;D:\kafka_2.12-2.3.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka_2.12-2.3.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka_2.12-2.3.0\libs\jaxb-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\jersey-client-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-common-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-hk2-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-server-2.28.jar;D:\kafka_2.12-2.3.0\libs\jetty-client-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-continuation-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-http-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-io-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-security-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-server-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlet-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlets-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-util-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jopt-simple-5.0.4.jar;D:\kafka_2.12-2.3.0\libs\jsr305-3.0.2.jar;D:\kafka_2.12-2.3.0\libs\kafka-clients-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-log4j-appender-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-examples-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-scala_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-test-utils-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-tools-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar.asc;D:\kafka_2.12-2.3.0\libs\log4j-1.2.17.jar;D:\kafka_2.12-2.3.0\libs\lz4-java-1.6.0.jar;D:\kafka_2.12-2.3.0\libs\maven-artifact-3.6.1.jar;D:\kafka_2.12-2.3.0\libs\metrics-core-2.2.0.jar;D:\kafka_2.12-2.3.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka_2.12-2.3.0\libs\paranamer-2.8.jar;D:\kafka_2.12-2.3.0\libs\plexus-utils-3.2.0.jar;D:\kafka_2.12-2.3.0\libs\reflections-0.9.11.jar;D:\kafka_2.12-2.3.0\libs\rocksdbjni-5.18.3.jar;D:\kafka_2.12-2.3.0\libs\scala-library-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\scala-logging_2.12-3.9.0.jar;D:\kafka_2.12-2.3.0\libs\scala-reflect-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\slf4j-api-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\slf4j-log4j12-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\snappy-java-1.1.7.3.jar;D:\kafka_2.12-2.3.0\libs\spotbugs-annotations-3.1.9.jar;D:\kafka_2.12-2.3.0\libs\validation-api-2.0.1.Final.jar;D:\kafka_2.12-2.3.0\libs\zkclient-0.11.jar;D:\kafka_2.12-2.3.0\libs\zookeeper-3.4.14.jar;D:\kafka_2.12-2.3.0\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,665] INFO Client environment:java.library.path=D:\java\jdk\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\Java\jdk1.8.0_73\bin;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;D:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\ManagementStudio\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;D:\confluent-5.2.2\bin;D:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\saksham.aggarwal\AppData\Local\atom\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,668] INFO Client environment:java.io.tmpdir=C:\Users\SAKSHA~1.AGG\AppData\Local\Temp\2\ (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,669] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,670] INFO Client environment:os.name=Windows Server 2012 R2 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,671] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,672] INFO Client environment:os.version=6.3 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,673] INFO Client environment:user.name=saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,674] INFO Client environment:user.home=C:\Users\saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,675] INFO Client environment:user.dir=D:\kafka_2.12-2.3.0\bin\windows (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,677] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@648c94da (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:36:18,699] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:36:18,704] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:36:18,708] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:64125 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-14 09:36:18,708] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:36:18,711] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:64125 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:36:18,714] INFO Established session 0x10014e807610002 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:64125 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:36:18,715] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10014e807610002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:36:18,720] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:36:18,761] INFO Got user-level KeeperException when processing sessionid:0x10014e807610002 type:create cxid:0x1 zxid:0x220 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,774] INFO Got user-level KeeperException when processing sessionid:0x10014e807610002 type:create cxid:0x2 zxid:0x221 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,777] INFO Got user-level KeeperException when processing sessionid:0x10014e807610002 type:create cxid:0x3 zxid:0x222 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,780] INFO Got user-level KeeperException when processing sessionid:0x10014e807610002 type:create cxid:0x4 zxid:0x223 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,787] INFO Got user-level KeeperException when processing sessionid:0x10014e807610002 type:create cxid:0x5 zxid:0x224 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,790] INFO Got user-level KeeperException when processing sessionid:0x10014e807610002 type:create cxid:0x6 zxid:0x225 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,792] INFO Got user-level KeeperException when processing sessionid:0x10014e807610002 type:create cxid:0x7 zxid:0x226 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,795] INFO Got user-level KeeperException when processing sessionid:0x10014e807610002 type:create cxid:0x8 zxid:0x227 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,798] INFO Got user-level KeeperException when processing sessionid:0x10014e807610002 type:create cxid:0x9 zxid:0x228 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,800] INFO Got user-level KeeperException when processing sessionid:0x10014e807610002 type:create cxid:0xa zxid:0x229 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,803] INFO Got user-level KeeperException when processing sessionid:0x10014e807610002 type:create cxid:0xb zxid:0x22a txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,811] INFO Got user-level KeeperException when processing sessionid:0x10014e807610002 type:create cxid:0xc zxid:0x22b txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,813] INFO Got user-level KeeperException when processing sessionid:0x10014e807610002 type:create cxid:0xd zxid:0x22c txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:36:18,974] INFO Cluster ID = Bx_HGZA6SbGgI2xxf7icgw (kafka.server.KafkaServer)
[2019-08-14 09:36:19,037] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 09:36:19,088] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 09:36:19,150] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:36:19,152] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:36:19,150] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:36:19,219] INFO Loading logs. (kafka.log.LogManager)
[2019-08-14 09:36:19,276] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,278] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,327] INFO [ProducerStateManager partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,350] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,352] INFO [ProducerStateManager partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,364] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 112 ms (kafka.log.Log)
[2019-08-14 09:36:19,378] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,379] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,384] INFO [ProducerStateManager partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,389] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,391] INFO [ProducerStateManager partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,392] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-08-14 09:36:19,398] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,399] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,404] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,406] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 10 ms (kafka.log.Log)
[2019-08-14 09:36:19,412] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,413] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,417] INFO [ProducerStateManager partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,423] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,425] INFO [ProducerStateManager partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,427] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 17 ms (kafka.log.Log)
[2019-08-14 09:36:19,432] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,433] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,437] INFO [ProducerStateManager partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,442] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,444] INFO [ProducerStateManager partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,445] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:36:19,450] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,451] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,456] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,458] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 9 ms (kafka.log.Log)
[2019-08-14 09:36:19,463] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,464] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,467] INFO [ProducerStateManager partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,473] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,474] INFO [ProducerStateManager partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,476] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:36:19,481] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,482] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,487] INFO [ProducerStateManager partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,492] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,494] INFO [ProducerStateManager partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,495] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-08-14 09:36:19,500] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,501] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,506] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,508] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 10 ms (kafka.log.Log)
[2019-08-14 09:36:19,513] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,514] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,518] INFO [ProducerStateManager partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,522] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,524] INFO [ProducerStateManager partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,526] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:36:19,531] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,532] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,538] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,543] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,546] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,547] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 18 ms (kafka.log.Log)
[2019-08-14 09:36:19,552] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,553] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,557] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,562] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,563] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,565] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:36:19,570] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,571] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,576] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,577] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 4 and log end offset 4 in 9 ms (kafka.log.Log)
[2019-08-14 09:36:19,582] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,583] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,587] INFO [ProducerStateManager partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,591] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,593] INFO [ProducerStateManager partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,595] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:36:19,602] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,603] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,607] INFO [ProducerStateManager partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,612] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,614] INFO [ProducerStateManager partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,615] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:36:19,620] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,621] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,625] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,627] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 9 ms (kafka.log.Log)
[2019-08-14 09:36:19,632] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,633] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,637] INFO [ProducerStateManager partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,641] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,643] INFO [ProducerStateManager partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,645] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:36:19,650] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,650] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,654] INFO [ProducerStateManager partition=cwct-producer-test-1-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,658] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,660] INFO [ProducerStateManager partition=cwct-producer-test-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-1-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,661] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 13 ms (kafka.log.Log)
[2019-08-14 09:36:19,665] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,666] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,674] INFO [ProducerStateManager partition=cwct-producer-test-2-0] Writing producer snapshot at offset 34 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,679] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 34 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,680] INFO [ProducerStateManager partition=cwct-producer-test-2-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-2-0\00000000000000000034.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,681] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 34 in 18 ms (kafka.log.Log)
[2019-08-14 09:36:19,685] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,686] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,691] INFO [ProducerStateManager partition=cwct-producer-test-3-0] Writing producer snapshot at offset 33 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,696] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 33 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,698] INFO [ProducerStateManager partition=cwct-producer-test-3-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-3-0\00000000000000000033.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,699] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 33 in 15 ms (kafka.log.Log)
[2019-08-14 09:36:19,703] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,704] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,708] INFO [ProducerStateManager partition=cwct-producer-test-4-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,713] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,715] INFO [ProducerStateManager partition=cwct-producer-test-4-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-4-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,716] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 15 ms (kafka.log.Log)
[2019-08-14 09:36:19,720] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,721] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,728] INFO [ProducerStateManager partition=cwct-producer-test-5-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,733] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,734] INFO [ProducerStateManager partition=cwct-producer-test-5-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-5-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,735] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 17 ms (kafka.log.Log)
[2019-08-14 09:36:19,739] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,740] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,744] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,745] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:36:19,752] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,752] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,757] INFO [ProducerStateManager partition=cwct-stream-input-test-1-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,761] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,763] INFO [ProducerStateManager partition=cwct-stream-input-test-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-stream-input-test-1-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,764] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 16 ms (kafka.log.Log)
[2019-08-14 09:36:19,768] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,769] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,773] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,774] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:36:19,778] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,779] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,783] INFO [ProducerStateManager partition=cwct-stream-test-1-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,787] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,789] INFO [ProducerStateManager partition=cwct-stream-test-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-stream-test-1-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,790] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 14 ms (kafka.log.Log)
[2019-08-14 09:36:19,794] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,794] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,798] INFO [ProducerStateManager partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,803] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,804] INFO [ProducerStateManager partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,806] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 14 ms (kafka.log.Log)
[2019-08-14 09:36:19,810] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,811] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,815] INFO [ProducerStateManager partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,819] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,821] INFO [ProducerStateManager partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,822] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 14 ms (kafka.log.Log)
[2019-08-14 09:36:19,826] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,827] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,832] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,833] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 9 ms (kafka.log.Log)
[2019-08-14 09:36:19,838] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,838] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,842] INFO [ProducerStateManager partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,847] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,849] INFO [ProducerStateManager partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,850] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 14 ms (kafka.log.Log)
[2019-08-14 09:36:19,855] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,855] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,859] INFO [ProducerStateManager partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,864] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,866] INFO [ProducerStateManager partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,867] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 14 ms (kafka.log.Log)
[2019-08-14 09:36:19,871] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,872] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,876] INFO [ProducerStateManager partition=key-based-events-1-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,881] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,882] INFO [ProducerStateManager partition=key-based-events-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\key-based-events-1-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,883] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 13 ms (kafka.log.Log)
[2019-08-14 09:36:19,888] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,888] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,892] INFO [ProducerStateManager partition=test-http-producer-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,896] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,897] INFO [ProducerStateManager partition=test-http-producer-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\test-http-producer-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,898] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 12 ms (kafka.log.Log)
[2019-08-14 09:36:19,902] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,912] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,916] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,922] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,923] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,924] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 24 ms (kafka.log.Log)
[2019-08-14 09:36:19,928] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,929] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,932] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,936] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,937] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,938] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:36:19,942] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,943] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,946] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,950] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,951] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-10\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,952] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:36:19,956] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,957] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,960] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,965] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,967] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,968] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 12 in 13 ms (kafka.log.Log)
[2019-08-14 09:36:19,971] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,972] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,975] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,977] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:36:19,980] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,981] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,984] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,988] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,990] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:19,991] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 12 ms (kafka.log.Log)
[2019-08-14 09:36:19,994] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:19,995] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:19,999] INFO [ProducerStateManager partition=__consumer_offsets-14] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,003] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,005] INFO [ProducerStateManager partition=__consumer_offsets-14] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-14\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,006] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 13 ms (kafka.log.Log)
[2019-08-14 09:36:20,009] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,010] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,013] INFO [ProducerStateManager partition=__consumer_offsets-15] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,018] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,019] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-15\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,020] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:36:20,024] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,025] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,028] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,033] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,034] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,035] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 13 ms (kafka.log.Log)
[2019-08-14 09:36:20,039] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,040] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,043] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,048] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,050] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,051] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 14 ms (kafka.log.Log)
[2019-08-14 09:36:20,054] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-08-14 09:36:20,056] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.index (kafka.log.Log)
[2019-08-14 09:36:20,057] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-08-14 09:36:20,058] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.log (kafka.log.Log)
[2019-08-14 09:36:20,060] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.log (kafka.log.Log)
[2019-08-14 09:36:20,063] ERROR [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Could not find offset index file corresponding to log file D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-14 09:36:20,064] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,068] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,070] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 11 (kafka.log.Log)
[2019-08-14 09:36:20,071] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,072] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,075] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,079] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,080] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,081] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 12 in 28 ms (kafka.log.Log)
[2019-08-14 09:36:20,085] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,085] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,089] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,094] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,095] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,096] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 13 ms (kafka.log.Log)
[2019-08-14 09:36:20,100] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,100] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,104] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,105] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:36:20,109] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,109] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,113] INFO [ProducerStateManager partition=__consumer_offsets-20] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,116] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,118] INFO [ProducerStateManager partition=__consumer_offsets-20] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-20\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,119] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 12 ms (kafka.log.Log)
[2019-08-14 09:36:20,134] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,135] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,138] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,142] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,144] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,145] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 24 ms (kafka.log.Log)
[2019-08-14 09:36:20,148] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,149] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,152] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,154] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:36:20,158] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,158] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,162] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,166] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,168] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,169] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 13 ms (kafka.log.Log)
[2019-08-14 09:36:20,172] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,173] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,176] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,188] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,190] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,191] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 20 ms (kafka.log.Log)
[2019-08-14 09:36:20,194] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,195] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,198] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,199] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:36:20,202] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,203] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,206] INFO [ProducerStateManager partition=__consumer_offsets-26] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,210] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,211] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-26\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,212] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,216] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,217] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,220] INFO [ProducerStateManager partition=__consumer_offsets-27] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,225] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 20 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,226] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-27\00000000000000000020.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,227] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 20 in 13 ms (kafka.log.Log)
[2019-08-14 09:36:20,230] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,231] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,234] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,238] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,239] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,240] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,243] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,244] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,247] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,249] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:36:20,252] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,252] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,256] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,261] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,263] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,264] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 14 ms (kafka.log.Log)
[2019-08-14 09:36:20,267] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,267] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,270] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,274] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,276] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,277] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-08-14 09:36:20,280] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,281] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,284] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,288] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,289] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,290] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-08-14 09:36:20,293] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,294] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,297] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,299] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:36:20,302] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,302] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,305] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,311] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,313] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-33\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,314] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 14 ms (kafka.log.Log)
[2019-08-14 09:36:20,317] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,317] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,320] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,324] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,325] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,326] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,329] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,330] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,333] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,337] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,339] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-35\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,340] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:36:20,343] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,344] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,347] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,351] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,352] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,353] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 12 ms (kafka.log.Log)
[2019-08-14 09:36:20,356] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,357] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,360] INFO [ProducerStateManager partition=__consumer_offsets-37] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,364] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,365] INFO [ProducerStateManager partition=__consumer_offsets-37] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-37\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,366] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,369] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,370] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,373] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,377] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,379] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-38\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,380] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:36:20,383] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,383] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,386] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,390] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,391] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,392] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,395] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,395] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,398] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,400] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:36:20,403] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,404] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,407] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,408] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 09:36:20,411] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,411] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,414] INFO [ProducerStateManager partition=__consumer_offsets-41] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,419] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,420] INFO [ProducerStateManager partition=__consumer_offsets-41] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-41\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,421] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,424] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,425] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,428] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 19 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,432] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 19 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,433] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000019.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,434] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 19 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,437] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,438] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,441] INFO [ProducerStateManager partition=__consumer_offsets-43] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,445] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,446] INFO [ProducerStateManager partition=__consumer_offsets-43] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-43\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,447] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,450] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,450] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,453] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,455] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:36:20,457] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,458] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,461] INFO [ProducerStateManager partition=__consumer_offsets-45] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,465] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,466] INFO [ProducerStateManager partition=__consumer_offsets-45] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-45\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,467] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,470] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,471] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,474] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,477] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,479] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,480] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,482] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,483] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,486] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,490] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,492] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,493] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-08-14 09:36:20,495] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,496] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,499] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,503] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,504] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-48\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,505] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,508] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,508] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,512] INFO [ProducerStateManager partition=__consumer_offsets-49] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,516] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,517] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,518] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,521] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,522] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,525] INFO [ProducerStateManager partition=__consumer_offsets-5] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,529] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,530] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,531] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,534] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,534] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,537] INFO [ProducerStateManager partition=__consumer_offsets-6] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,541] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,542] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-6\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,543] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,546] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,547] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,550] INFO [ProducerStateManager partition=__consumer_offsets-7] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,554] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,556] INFO [ProducerStateManager partition=__consumer_offsets-7] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-7\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,557] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-08-14 09:36:20,568] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,569] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,572] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,577] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,578] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-8\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,579] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 21 ms (kafka.log.Log)
[2019-08-14 09:36:20,582] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:36:20,582] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,586] INFO [ProducerStateManager partition=__consumer_offsets-9] Writing producer snapshot at offset 14 (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,590] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 14 with message format version 2 (kafka.log.Log)
[2019-08-14 09:36:20,591] INFO [ProducerStateManager partition=__consumer_offsets-9] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000014.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:36:20,592] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 14 in 11 ms (kafka.log.Log)
[2019-08-14 09:36:20,595] INFO Logs loading complete in 1375 ms. (kafka.log.LogManager)
[2019-08-14 09:36:20,607] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-14 09:36:20,609] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-14 09:36:20,857] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2016)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2016)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2016)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-08-14 09:36:20,931] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:270)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1180)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-08-14 09:36:20,950] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-14 09:36:20,983] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:270)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1180)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-08-14 09:36:21,041] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-08-14 09:36:21,041] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:270)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1180)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-08-14 09:36:21,043] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-08-14 09:36:21,097] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:270)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1180)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-08-14 09:36:21,112] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:36:21,113] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:36:21,116] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:36:21,126] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:36:21,162] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-14 09:36:21,166] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-08-14 09:36:21,170] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2016)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2016)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2016)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-08-14 09:36:21,189] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-08-14 09:36:21,192] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-08-14 09:36:21,199] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-08-14 09:36:21,553] WARN Exception causing close of session 0x10014e807610002: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-14 09:36:21,554] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:64125 which had sessionid 0x10014e807610002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-14 09:36:29,870] INFO Expiring session 0x10014e807610002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:36:29,870] INFO Processed session termination for sessionid: 0x10014e807610002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:26,537] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-08-14 09:37:26,541] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 09:37:26,541] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 09:37:26,541] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 09:37:26,542] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-08-14 09:37:26,558] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-08-14 09:37:26,559] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-08-14 09:37:26,570] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,570] INFO Server environment:host.name=SAKSHAMA2012.pacific.costcotravel.com (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,571] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,571] INFO Server environment:java.vendor=AdoptOpenJDK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,572] INFO Server environment:java.home=D:\java\jdk (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,573] INFO Server environment:java.class.path=..;D:\kafka_2.12-2.3.0\libs\activation-1.1.1.jar;D:\kafka_2.12-2.3.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\argparse4j-0.7.0.jar;D:\kafka_2.12-2.3.0\libs\audience-annotations-0.5.0.jar;D:\kafka_2.12-2.3.0\libs\commons-lang3-3.8.1.jar;D:\kafka_2.12-2.3.0\libs\connect-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-basic-auth-extension-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-file-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-json-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-runtime-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-transforms-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\guava-20.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-api-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-locator-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-utils-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jackson-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-core-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-databind-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-dataformat-csv-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-datatype-jdk8-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-base-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-json-provider-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-jaxb-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-paranamer-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-scala_2.12-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka_2.12-2.3.0\libs\jakarta.inject-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka_2.12-2.3.0\libs\javassist-3.22.0-CR2.jar;D:\kafka_2.12-2.3.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka_2.12-2.3.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka_2.12-2.3.0\libs\jaxb-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\jersey-client-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-common-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-hk2-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-server-2.28.jar;D:\kafka_2.12-2.3.0\libs\jetty-client-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-continuation-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-http-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-io-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-security-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-server-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlet-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlets-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-util-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jopt-simple-5.0.4.jar;D:\kafka_2.12-2.3.0\libs\jsr305-3.0.2.jar;D:\kafka_2.12-2.3.0\libs\kafka-clients-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-log4j-appender-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-examples-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-scala_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-test-utils-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-tools-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar.asc;D:\kafka_2.12-2.3.0\libs\log4j-1.2.17.jar;D:\kafka_2.12-2.3.0\libs\lz4-java-1.6.0.jar;D:\kafka_2.12-2.3.0\libs\maven-artifact-3.6.1.jar;D:\kafka_2.12-2.3.0\libs\metrics-core-2.2.0.jar;D:\kafka_2.12-2.3.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka_2.12-2.3.0\libs\paranamer-2.8.jar;D:\kafka_2.12-2.3.0\libs\plexus-utils-3.2.0.jar;D:\kafka_2.12-2.3.0\libs\reflections-0.9.11.jar;D:\kafka_2.12-2.3.0\libs\rocksdbjni-5.18.3.jar;D:\kafka_2.12-2.3.0\libs\scala-library-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\scala-logging_2.12-3.9.0.jar;D:\kafka_2.12-2.3.0\libs\scala-reflect-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\slf4j-api-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\slf4j-log4j12-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\snappy-java-1.1.7.3.jar;D:\kafka_2.12-2.3.0\libs\spotbugs-annotations-3.1.9.jar;D:\kafka_2.12-2.3.0\libs\validation-api-2.0.1.Final.jar;D:\kafka_2.12-2.3.0\libs\zkclient-0.11.jar;D:\kafka_2.12-2.3.0\libs\zookeeper-3.4.14.jar;D:\kafka_2.12-2.3.0\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,590] INFO Server environment:java.library.path=D:\java\jdk\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\Java\jdk1.8.0_73\bin;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;D:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\ManagementStudio\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;D:\confluent-5.2.2\bin;D:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\saksham.aggarwal\AppData\Local\atom\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,594] INFO Server environment:java.io.tmpdir=C:\Users\SAKSHA~1.AGG\AppData\Local\Temp\2\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,595] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,596] INFO Server environment:os.name=Windows Server 2012 R2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,596] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,597] INFO Server environment:os.version=6.3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,598] INFO Server environment:user.name=saksham.aggarwal (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,599] INFO Server environment:user.home=C:\Users\saksham.aggarwal (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,600] INFO Server environment:user.dir=D:\kafka_2.12-2.3.0\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,609] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,610] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,611] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:26,630] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-08-14 09:37:26,633] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-14 09:37:30,445] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-14 09:37:30,996] INFO starting (kafka.server.KafkaServer)
[2019-08-14 09:37:30,997] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-14 09:37:31,032] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:37:31,039] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,040] INFO Client environment:host.name=SAKSHAMA2012.pacific.costcotravel.com (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,040] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,040] INFO Client environment:java.vendor=AdoptOpenJDK (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,041] INFO Client environment:java.home=D:\java\jdk (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,041] INFO Client environment:java.class.path=..;D:\kafka_2.12-2.3.0\libs\activation-1.1.1.jar;D:\kafka_2.12-2.3.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\argparse4j-0.7.0.jar;D:\kafka_2.12-2.3.0\libs\audience-annotations-0.5.0.jar;D:\kafka_2.12-2.3.0\libs\commons-lang3-3.8.1.jar;D:\kafka_2.12-2.3.0\libs\connect-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-basic-auth-extension-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-file-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-json-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-runtime-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-transforms-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\guava-20.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-api-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-locator-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-utils-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jackson-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-core-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-databind-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-dataformat-csv-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-datatype-jdk8-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-base-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-json-provider-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-jaxb-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-paranamer-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-scala_2.12-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka_2.12-2.3.0\libs\jakarta.inject-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka_2.12-2.3.0\libs\javassist-3.22.0-CR2.jar;D:\kafka_2.12-2.3.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka_2.12-2.3.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka_2.12-2.3.0\libs\jaxb-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\jersey-client-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-common-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-hk2-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-server-2.28.jar;D:\kafka_2.12-2.3.0\libs\jetty-client-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-continuation-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-http-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-io-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-security-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-server-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlet-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlets-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-util-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jopt-simple-5.0.4.jar;D:\kafka_2.12-2.3.0\libs\jsr305-3.0.2.jar;D:\kafka_2.12-2.3.0\libs\kafka-clients-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-log4j-appender-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-examples-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-scala_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-test-utils-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-tools-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar.asc;D:\kafka_2.12-2.3.0\libs\log4j-1.2.17.jar;D:\kafka_2.12-2.3.0\libs\lz4-java-1.6.0.jar;D:\kafka_2.12-2.3.0\libs\maven-artifact-3.6.1.jar;D:\kafka_2.12-2.3.0\libs\metrics-core-2.2.0.jar;D:\kafka_2.12-2.3.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka_2.12-2.3.0\libs\paranamer-2.8.jar;D:\kafka_2.12-2.3.0\libs\plexus-utils-3.2.0.jar;D:\kafka_2.12-2.3.0\libs\reflections-0.9.11.jar;D:\kafka_2.12-2.3.0\libs\rocksdbjni-5.18.3.jar;D:\kafka_2.12-2.3.0\libs\scala-library-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\scala-logging_2.12-3.9.0.jar;D:\kafka_2.12-2.3.0\libs\scala-reflect-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\slf4j-api-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\slf4j-log4j12-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\snappy-java-1.1.7.3.jar;D:\kafka_2.12-2.3.0\libs\spotbugs-annotations-3.1.9.jar;D:\kafka_2.12-2.3.0\libs\validation-api-2.0.1.Final.jar;D:\kafka_2.12-2.3.0\libs\zkclient-0.11.jar;D:\kafka_2.12-2.3.0\libs\zookeeper-3.4.14.jar;D:\kafka_2.12-2.3.0\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,055] INFO Client environment:java.library.path=D:\java\jdk\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\Java\jdk1.8.0_73\bin;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;D:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\ManagementStudio\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;D:\confluent-5.2.2\bin;D:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\saksham.aggarwal\AppData\Local\atom\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,059] INFO Client environment:java.io.tmpdir=C:\Users\SAKSHA~1.AGG\AppData\Local\Temp\2\ (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,059] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,060] INFO Client environment:os.name=Windows Server 2012 R2 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,061] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,062] INFO Client environment:os.version=6.3 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,063] INFO Client environment:user.name=saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,064] INFO Client environment:user.home=C:\Users\saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,064] INFO Client environment:user.dir=D:\kafka_2.12-2.3.0\bin\windows (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,067] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@648c94da (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:37:31,090] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:37:31,092] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:37:31,096] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:37:31,097] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:64155 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-14 09:37:31,105] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:64155 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:31,107] INFO Creating new log file: log.22e (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-08-14 09:37:31,114] INFO Established session 0x100153f82fd0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:64155 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:37:31,116] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100153f82fd0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:37:31,120] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:37:31,163] INFO Got user-level KeeperException when processing sessionid:0x100153f82fd0000 type:create cxid:0x1 zxid:0x22f txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:31,178] INFO Got user-level KeeperException when processing sessionid:0x100153f82fd0000 type:create cxid:0x2 zxid:0x230 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:31,182] INFO Got user-level KeeperException when processing sessionid:0x100153f82fd0000 type:create cxid:0x3 zxid:0x231 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:31,186] INFO Got user-level KeeperException when processing sessionid:0x100153f82fd0000 type:create cxid:0x4 zxid:0x232 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:31,195] INFO Got user-level KeeperException when processing sessionid:0x100153f82fd0000 type:create cxid:0x5 zxid:0x233 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:31,198] INFO Got user-level KeeperException when processing sessionid:0x100153f82fd0000 type:create cxid:0x6 zxid:0x234 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:31,202] INFO Got user-level KeeperException when processing sessionid:0x100153f82fd0000 type:create cxid:0x7 zxid:0x235 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:31,205] INFO Got user-level KeeperException when processing sessionid:0x100153f82fd0000 type:create cxid:0x8 zxid:0x236 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:31,208] INFO Got user-level KeeperException when processing sessionid:0x100153f82fd0000 type:create cxid:0x9 zxid:0x237 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:31,212] INFO Got user-level KeeperException when processing sessionid:0x100153f82fd0000 type:create cxid:0xa zxid:0x238 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:31,215] INFO Got user-level KeeperException when processing sessionid:0x100153f82fd0000 type:create cxid:0xb zxid:0x239 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:31,218] INFO Got user-level KeeperException when processing sessionid:0x100153f82fd0000 type:create cxid:0xc zxid:0x23a txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:31,220] INFO Got user-level KeeperException when processing sessionid:0x100153f82fd0000 type:create cxid:0xd zxid:0x23b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:37:31,378] INFO Cluster ID = Bx_HGZA6SbGgI2xxf7icgw (kafka.server.KafkaServer)
[2019-08-14 09:37:31,447] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 09:37:31,499] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 09:37:31,563] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:37:31,565] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:37:31,563] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:37:31,639] INFO Loading logs. (kafka.log.LogManager)
[2019-08-14 09:37:31,702] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:31,705] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,757] INFO [ProducerStateManager partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,776] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,779] INFO [ProducerStateManager partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,790] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 116 ms (kafka.log.Log)
[2019-08-14 09:37:31,805] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:31,806] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,810] INFO [ProducerStateManager partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,815] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,817] INFO [ProducerStateManager partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,819] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-08-14 09:37:31,824] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:31,825] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,833] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,834] INFO [Log partition=1da6ba26-32f5-4751-8939-0f7a3954df45-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:31,840] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:31,841] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,845] INFO [ProducerStateManager partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,850] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,852] INFO [ProducerStateManager partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,853] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:37:31,859] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:31,860] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,864] INFO [ProducerStateManager partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,868] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,870] INFO [ProducerStateManager partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,872] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:37:31,877] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:31,878] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,883] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,884] INFO [Log partition=31b72962-71d9-4880-b24d-2c40810955a6-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 9 ms (kafka.log.Log)
[2019-08-14 09:37:31,890] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:31,891] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,895] INFO [ProducerStateManager partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,900] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,902] INFO [ProducerStateManager partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,904] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-08-14 09:37:31,909] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:31,910] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,914] INFO [ProducerStateManager partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,922] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,929] INFO [ProducerStateManager partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,930] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 23 ms (kafka.log.Log)
[2019-08-14 09:37:31,936] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:31,937] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,942] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,944] INFO [Log partition=32e7965d-8736-4377-a894-348ae45606a1-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 10 ms (kafka.log.Log)
[2019-08-14 09:37:31,949] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:31,950] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,954] INFO [ProducerStateManager partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,959] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,961] INFO [ProducerStateManager partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,962] INFO [Log partition=40b5a322-1084-4d88-9035-5640d6e2dddb-key-based-events-1-STATE-STORE-0000000003-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:37:31,967] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:31,968] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,973] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,977] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,979] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,981] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:37:31,986] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:31,987] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,990] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,995] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:31,997] INFO [ProducerStateManager partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:31,998] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 14 ms (kafka.log.Log)
[2019-08-14 09:37:32,003] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,004] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,008] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,010] INFO [Log partition=476947f3-f64f-40a5-aa43-fea377e6df90-events-store-test-1-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 4 and log end offset 4 in 8 ms (kafka.log.Log)
[2019-08-14 09:37:32,015] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,016] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,020] INFO [ProducerStateManager partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,025] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,026] INFO [ProducerStateManager partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,028] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:37:32,033] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,034] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,038] INFO [ProducerStateManager partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,042] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,044] INFO [ProducerStateManager partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,046] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 15 ms (kafka.log.Log)
[2019-08-14 09:37:32,051] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,052] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,056] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,058] INFO [Log partition=64907477-1a30-44ca-aba9-921bdb9571ca-KTABLE-AGGREGATE-STATE-STORE-0000000004-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 9 ms (kafka.log.Log)
[2019-08-14 09:37:32,063] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,064] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,067] INFO [ProducerStateManager partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,073] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,084] INFO [ProducerStateManager partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,085] INFO [Log partition=79964e0b-38f1-4dcb-bf16-876455cd1e42-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 24 ms (kafka.log.Log)
[2019-08-14 09:37:32,090] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,090] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,094] INFO [ProducerStateManager partition=cwct-producer-test-1-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,098] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,100] INFO [ProducerStateManager partition=cwct-producer-test-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-1-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,101] INFO [Log partition=cwct-producer-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 13 ms (kafka.log.Log)
[2019-08-14 09:37:32,105] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,106] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,114] INFO [ProducerStateManager partition=cwct-producer-test-2-0] Writing producer snapshot at offset 34 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,118] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 34 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,120] INFO [ProducerStateManager partition=cwct-producer-test-2-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-2-0\00000000000000000034.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,121] INFO [Log partition=cwct-producer-test-2-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 34 in 18 ms (kafka.log.Log)
[2019-08-14 09:37:32,125] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,126] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,130] INFO [ProducerStateManager partition=cwct-producer-test-3-0] Writing producer snapshot at offset 33 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,135] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 33 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,136] INFO [ProducerStateManager partition=cwct-producer-test-3-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-3-0\00000000000000000033.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,137] INFO [Log partition=cwct-producer-test-3-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 33 in 14 ms (kafka.log.Log)
[2019-08-14 09:37:32,142] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,143] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,147] INFO [ProducerStateManager partition=cwct-producer-test-4-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,151] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,153] INFO [ProducerStateManager partition=cwct-producer-test-4-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-4-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,154] INFO [Log partition=cwct-producer-test-4-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 14 ms (kafka.log.Log)
[2019-08-14 09:37:32,158] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,158] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,162] INFO [ProducerStateManager partition=cwct-producer-test-5-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,167] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,168] INFO [ProducerStateManager partition=cwct-producer-test-5-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-producer-test-5-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,169] INFO [Log partition=cwct-producer-test-5-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 13 ms (kafka.log.Log)
[2019-08-14 09:37:32,173] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,174] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,178] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,179] INFO [Log partition=cwct-stream-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:37:32,183] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,184] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,187] INFO [ProducerStateManager partition=cwct-stream-input-test-1-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,191] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,193] INFO [ProducerStateManager partition=cwct-stream-input-test-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-stream-input-test-1-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,194] INFO [Log partition=cwct-stream-input-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 13 ms (kafka.log.Log)
[2019-08-14 09:37:32,198] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,199] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,202] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,204] INFO [Log partition=cwct-stream-output-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:37:32,208] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,208] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,212] INFO [ProducerStateManager partition=cwct-stream-test-1-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,218] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,219] INFO [ProducerStateManager partition=cwct-stream-test-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\cwct-stream-test-1-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,220] INFO [Log partition=cwct-stream-test-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 14 ms (kafka.log.Log)
[2019-08-14 09:37:32,224] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,225] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,229] INFO [ProducerStateManager partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,233] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,235] INFO [ProducerStateManager partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,236] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-key-based-events-1-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 14 ms (kafka.log.Log)
[2019-08-14 09:37:32,240] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,241] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,245] INFO [ProducerStateManager partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,249] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,251] INFO [ProducerStateManager partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,253] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 14 ms (kafka.log.Log)
[2019-08-14 09:37:32,256] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,257] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,262] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,263] INFO [Log partition=d92994d3-4f79-4b40-aa5c-cde2e87251d9-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 3 and log end offset 3 in 8 ms (kafka.log.Log)
[2019-08-14 09:37:32,268] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,268] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,272] INFO [ProducerStateManager partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,277] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,279] INFO [ProducerStateManager partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,281] INFO [Log partition=dc884088-7f9b-49bb-9782-31f115e6c1d6-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 15 ms (kafka.log.Log)
[2019-08-14 09:37:32,285] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,285] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,289] INFO [ProducerStateManager partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,294] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,295] INFO [ProducerStateManager partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,297] INFO [Log partition=f715541f-3980-4394-9320-ef89bba0568d-cwct-producer-test-4-STATE-STORE-0000000000-changelog-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 14 ms (kafka.log.Log)
[2019-08-14 09:37:32,301] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,302] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,305] INFO [ProducerStateManager partition=key-based-events-1-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,309] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,310] INFO [ProducerStateManager partition=key-based-events-1-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\key-based-events-1-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,311] INFO [Log partition=key-based-events-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,315] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,316] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,319] INFO [ProducerStateManager partition=test-http-producer-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,323] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,325] INFO [ProducerStateManager partition=test-http-producer-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\test-http-producer-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,326] INFO [Log partition=test-http-producer-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 13 ms (kafka.log.Log)
[2019-08-14 09:37:32,330] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,330] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,333] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,339] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,340] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,341] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 13 ms (kafka.log.Log)
[2019-08-14 09:37:32,345] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,345] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,349] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,358] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,359] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,360] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 17 ms (kafka.log.Log)
[2019-08-14 09:37:32,364] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,364] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,368] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,373] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,375] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-10\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,376] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 14 ms (kafka.log.Log)
[2019-08-14 09:37:32,379] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,379] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,383] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,387] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,389] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,390] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 12 in 13 ms (kafka.log.Log)
[2019-08-14 09:37:32,393] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,394] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,397] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,398] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 09:37:32,402] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,403] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,406] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,410] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,412] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,413] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 13 ms (kafka.log.Log)
[2019-08-14 09:37:32,417] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,417] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,421] INFO [ProducerStateManager partition=__consumer_offsets-14] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,425] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,426] INFO [ProducerStateManager partition=__consumer_offsets-14] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-14\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,427] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,431] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,431] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,435] INFO [ProducerStateManager partition=__consumer_offsets-15] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,439] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,440] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-15\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,441] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,445] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,446] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,449] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,454] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,455] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,456] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 13 ms (kafka.log.Log)
[2019-08-14 09:37:32,459] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,460] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,463] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,470] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,471] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,472] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 14 ms (kafka.log.Log)
[2019-08-14 09:37:32,476] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-08-14 09:37:32,477] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.index (kafka.log.Log)
[2019-08-14 09:37:32,478] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-08-14 09:37:32,479] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.log (kafka.log.Log)
[2019-08-14 09:37:32,481] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.log (kafka.log.Log)
[2019-08-14 09:37:32,484] ERROR [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Could not find offset index file corresponding to log file D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-14 09:37:32,485] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,489] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,491] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 11 (kafka.log.Log)
[2019-08-14 09:37:32,491] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,493] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,495] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,499] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,501] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,502] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 12 in 28 ms (kafka.log.Log)
[2019-08-14 09:37:32,517] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,518] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,521] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,526] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,528] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,529] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 25 ms (kafka.log.Log)
[2019-08-14 09:37:32,532] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,533] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,536] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,537] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 09:37:32,541] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,541] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,545] INFO [ProducerStateManager partition=__consumer_offsets-20] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,550] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,551] INFO [ProducerStateManager partition=__consumer_offsets-20] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-20\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,552] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 13 ms (kafka.log.Log)
[2019-08-14 09:37:32,555] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,556] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,559] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,563] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,564] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,565] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 11 ms (kafka.log.Log)
[2019-08-14 09:37:32,569] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,569] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,573] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,574] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:37:32,578] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,579] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,582] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,586] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,587] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,588] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,592] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,592] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,595] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,609] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,610] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,611] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 21 ms (kafka.log.Log)
[2019-08-14 09:37:32,614] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,615] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,618] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,620] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:37:32,623] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,623] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,627] INFO [ProducerStateManager partition=__consumer_offsets-26] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,631] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,632] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-26\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,633] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,636] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,637] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,640] INFO [ProducerStateManager partition=__consumer_offsets-27] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,644] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 20 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,646] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-27\00000000000000000020.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,655] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 20 in 20 ms (kafka.log.Log)
[2019-08-14 09:37:32,659] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,659] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,663] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,667] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,668] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,669] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,672] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,673] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,676] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,678] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:37:32,681] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,681] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,685] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,688] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,690] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,691] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,694] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,695] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,698] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,702] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,703] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,704] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:37:32,707] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,708] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,711] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,715] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,717] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,718] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,721] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,721] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,724] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,726] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:37:32,729] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,730] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,733] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,737] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,738] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-33\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,739] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:37:32,742] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,743] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,746] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,750] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,751] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,752] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 11 ms (kafka.log.Log)
[2019-08-14 09:37:32,756] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,757] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,760] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,764] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,765] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-35\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,766] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,769] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,770] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,773] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,777] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,779] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,780] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,783] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,784] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,787] INFO [ProducerStateManager partition=__consumer_offsets-37] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,791] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,793] INFO [ProducerStateManager partition=__consumer_offsets-37] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-37\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,794] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,797] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,798] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,801] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,805] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,806] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-38\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,807] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,810] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,811] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,814] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,818] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,820] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,821] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,824] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,824] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,828] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,829] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-08-14 09:37:32,832] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,833] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,836] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,837] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 09:37:32,840] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,841] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,844] INFO [ProducerStateManager partition=__consumer_offsets-41] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,848] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,849] INFO [ProducerStateManager partition=__consumer_offsets-41] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-41\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,851] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,854] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,854] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,858] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 19 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,862] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 19 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,863] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000019.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,864] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 19 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,867] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,868] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,872] INFO [ProducerStateManager partition=__consumer_offsets-43] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,876] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,878] INFO [ProducerStateManager partition=__consumer_offsets-43] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-43\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,879] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 13 ms (kafka.log.Log)
[2019-08-14 09:37:32,882] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,883] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,886] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,887] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-08-14 09:37:32,890] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,891] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,894] INFO [ProducerStateManager partition=__consumer_offsets-45] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,898] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,899] INFO [ProducerStateManager partition=__consumer_offsets-45] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-45\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,900] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 11 ms (kafka.log.Log)
[2019-08-14 09:37:32,903] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,904] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,907] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,912] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,913] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,914] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,917] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,918] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,921] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,925] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,926] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,927] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 11 ms (kafka.log.Log)
[2019-08-14 09:37:32,930] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,931] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,934] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,938] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,940] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-48\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,941] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,945] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,946] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,949] INFO [ProducerStateManager partition=__consumer_offsets-49] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,954] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,955] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,956] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 13 ms (kafka.log.Log)
[2019-08-14 09:37:32,960] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,961] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,965] INFO [ProducerStateManager partition=__consumer_offsets-5] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,969] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,971] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,973] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 15 ms (kafka.log.Log)
[2019-08-14 09:37:32,976] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,976] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,979] INFO [ProducerStateManager partition=__consumer_offsets-6] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,983] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,985] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-6\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,986] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:32,990] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:32,990] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,994] INFO [ProducerStateManager partition=__consumer_offsets-7] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:32,998] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:32,999] INFO [ProducerStateManager partition=__consumer_offsets-7] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-7\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:33,000] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 12 ms (kafka.log.Log)
[2019-08-14 09:37:33,003] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:33,004] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:33,008] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:33,013] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:33,015] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-8\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:33,016] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 14 ms (kafka.log.Log)
[2019-08-14 09:37:33,019] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-14 09:37:33,020] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:33,024] INFO [ProducerStateManager partition=__consumer_offsets-9] Writing producer snapshot at offset 14 (kafka.log.ProducerStateManager)
[2019-08-14 09:37:33,029] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 14 with message format version 2 (kafka.log.Log)
[2019-08-14 09:37:33,030] INFO [ProducerStateManager partition=__consumer_offsets-9] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000014.snapshot' (kafka.log.ProducerStateManager)
[2019-08-14 09:37:33,031] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 14 in 13 ms (kafka.log.Log)
[2019-08-14 09:37:33,035] INFO Logs loading complete in 1395 ms. (kafka.log.LogManager)
[2019-08-14 09:37:33,048] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-14 09:37:33,050] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-14 09:37:33,289] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2016)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2016)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2016)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-08-14 09:37:33,363] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:270)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1180)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-08-14 09:37:33,393] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-14 09:37:33,403] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:270)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1180)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-08-14 09:37:33,438] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-08-14 09:37:33,440] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-08-14 09:37:33,460] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:270)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1180)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2293)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-08-14 09:37:33,496] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:37:33,497] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:37:33,497] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:37:33,497] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:37:33,527] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-14 09:37:33,530] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-08-14 09:37:33,536] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-08-14 09:37:33,537] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-08-14 09:37:33,540] ERROR Failed to clean up log for __consumer_offsets-18 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2016)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2016)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2016)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-08-14 09:37:33,541] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-08-14 09:37:33,890] WARN Exception causing close of session 0x100153f82fd0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-14 09:37:33,892] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:64155 which had sessionid 0x100153f82fd0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-14 09:38:28,714] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-08-14 09:38:28,717] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 09:38:28,717] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 09:38:28,718] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 09:38:28,718] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-08-14 09:38:28,734] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-08-14 09:38:28,735] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-08-14 09:38:28,745] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,745] INFO Server environment:host.name=SAKSHAMA2012.pacific.costcotravel.com (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,745] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,746] INFO Server environment:java.vendor=AdoptOpenJDK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,746] INFO Server environment:java.home=D:\java\jdk (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,748] INFO Server environment:java.class.path=..;D:\kafka_2.12-2.3.0\libs\activation-1.1.1.jar;D:\kafka_2.12-2.3.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\argparse4j-0.7.0.jar;D:\kafka_2.12-2.3.0\libs\audience-annotations-0.5.0.jar;D:\kafka_2.12-2.3.0\libs\commons-lang3-3.8.1.jar;D:\kafka_2.12-2.3.0\libs\connect-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-basic-auth-extension-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-file-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-json-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-runtime-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-transforms-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\guava-20.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-api-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-locator-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-utils-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jackson-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-core-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-databind-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-dataformat-csv-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-datatype-jdk8-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-base-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-json-provider-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-jaxb-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-paranamer-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-scala_2.12-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka_2.12-2.3.0\libs\jakarta.inject-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka_2.12-2.3.0\libs\javassist-3.22.0-CR2.jar;D:\kafka_2.12-2.3.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka_2.12-2.3.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka_2.12-2.3.0\libs\jaxb-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\jersey-client-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-common-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-hk2-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-server-2.28.jar;D:\kafka_2.12-2.3.0\libs\jetty-client-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-continuation-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-http-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-io-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-security-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-server-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlet-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlets-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-util-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jopt-simple-5.0.4.jar;D:\kafka_2.12-2.3.0\libs\jsr305-3.0.2.jar;D:\kafka_2.12-2.3.0\libs\kafka-clients-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-log4j-appender-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-examples-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-scala_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-test-utils-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-tools-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar.asc;D:\kafka_2.12-2.3.0\libs\log4j-1.2.17.jar;D:\kafka_2.12-2.3.0\libs\lz4-java-1.6.0.jar;D:\kafka_2.12-2.3.0\libs\maven-artifact-3.6.1.jar;D:\kafka_2.12-2.3.0\libs\metrics-core-2.2.0.jar;D:\kafka_2.12-2.3.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka_2.12-2.3.0\libs\paranamer-2.8.jar;D:\kafka_2.12-2.3.0\libs\plexus-utils-3.2.0.jar;D:\kafka_2.12-2.3.0\libs\reflections-0.9.11.jar;D:\kafka_2.12-2.3.0\libs\rocksdbjni-5.18.3.jar;D:\kafka_2.12-2.3.0\libs\scala-library-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\scala-logging_2.12-3.9.0.jar;D:\kafka_2.12-2.3.0\libs\scala-reflect-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\slf4j-api-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\slf4j-log4j12-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\snappy-java-1.1.7.3.jar;D:\kafka_2.12-2.3.0\libs\spotbugs-annotations-3.1.9.jar;D:\kafka_2.12-2.3.0\libs\validation-api-2.0.1.Final.jar;D:\kafka_2.12-2.3.0\libs\zkclient-0.11.jar;D:\kafka_2.12-2.3.0\libs\zookeeper-3.4.14.jar;D:\kafka_2.12-2.3.0\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,764] INFO Server environment:java.library.path=D:\java\jdk\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\Java\jdk1.8.0_73\bin;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;D:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\ManagementStudio\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;D:\confluent-5.2.2\bin;D:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\saksham.aggarwal\AppData\Local\atom\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,769] INFO Server environment:java.io.tmpdir=C:\Users\SAKSHA~1.AGG\AppData\Local\Temp\2\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,770] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,771] INFO Server environment:os.name=Windows Server 2012 R2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,772] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,772] INFO Server environment:os.version=6.3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,773] INFO Server environment:user.name=saksham.aggarwal (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,774] INFO Server environment:user.home=C:\Users\saksham.aggarwal (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,775] INFO Server environment:user.dir=D:\kafka_2.12-2.3.0\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,785] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,786] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,787] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:28,806] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-08-14 09:38:28,810] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-14 09:38:36,289] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-14 09:38:36,835] INFO starting (kafka.server.KafkaServer)
[2019-08-14 09:38:36,836] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-14 09:38:36,874] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:38:36,882] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,882] INFO Client environment:host.name=SAKSHAMA2012.pacific.costcotravel.com (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,882] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,882] INFO Client environment:java.vendor=AdoptOpenJDK (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,883] INFO Client environment:java.home=D:\java\jdk (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,883] INFO Client environment:java.class.path=..;D:\kafka_2.12-2.3.0\libs\activation-1.1.1.jar;D:\kafka_2.12-2.3.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\argparse4j-0.7.0.jar;D:\kafka_2.12-2.3.0\libs\audience-annotations-0.5.0.jar;D:\kafka_2.12-2.3.0\libs\commons-lang3-3.8.1.jar;D:\kafka_2.12-2.3.0\libs\connect-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-basic-auth-extension-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-file-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-json-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-runtime-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-transforms-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\guava-20.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-api-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-locator-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-utils-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jackson-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-core-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-databind-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-dataformat-csv-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-datatype-jdk8-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-base-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-json-provider-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-jaxb-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-paranamer-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-scala_2.12-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka_2.12-2.3.0\libs\jakarta.inject-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka_2.12-2.3.0\libs\javassist-3.22.0-CR2.jar;D:\kafka_2.12-2.3.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka_2.12-2.3.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka_2.12-2.3.0\libs\jaxb-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\jersey-client-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-common-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-hk2-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-server-2.28.jar;D:\kafka_2.12-2.3.0\libs\jetty-client-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-continuation-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-http-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-io-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-security-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-server-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlet-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlets-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-util-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jopt-simple-5.0.4.jar;D:\kafka_2.12-2.3.0\libs\jsr305-3.0.2.jar;D:\kafka_2.12-2.3.0\libs\kafka-clients-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-log4j-appender-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-examples-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-scala_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-test-utils-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-tools-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar.asc;D:\kafka_2.12-2.3.0\libs\log4j-1.2.17.jar;D:\kafka_2.12-2.3.0\libs\lz4-java-1.6.0.jar;D:\kafka_2.12-2.3.0\libs\maven-artifact-3.6.1.jar;D:\kafka_2.12-2.3.0\libs\metrics-core-2.2.0.jar;D:\kafka_2.12-2.3.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka_2.12-2.3.0\libs\paranamer-2.8.jar;D:\kafka_2.12-2.3.0\libs\plexus-utils-3.2.0.jar;D:\kafka_2.12-2.3.0\libs\reflections-0.9.11.jar;D:\kafka_2.12-2.3.0\libs\rocksdbjni-5.18.3.jar;D:\kafka_2.12-2.3.0\libs\scala-library-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\scala-logging_2.12-3.9.0.jar;D:\kafka_2.12-2.3.0\libs\scala-reflect-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\slf4j-api-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\slf4j-log4j12-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\snappy-java-1.1.7.3.jar;D:\kafka_2.12-2.3.0\libs\spotbugs-annotations-3.1.9.jar;D:\kafka_2.12-2.3.0\libs\validation-api-2.0.1.Final.jar;D:\kafka_2.12-2.3.0\libs\zkclient-0.11.jar;D:\kafka_2.12-2.3.0\libs\zookeeper-3.4.14.jar;D:\kafka_2.12-2.3.0\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,898] INFO Client environment:java.library.path=D:\java\jdk\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\Java\jdk1.8.0_73\bin;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;D:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\ManagementStudio\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;D:\confluent-5.2.2\bin;D:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\saksham.aggarwal\AppData\Local\atom\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,901] INFO Client environment:java.io.tmpdir=C:\Users\SAKSHA~1.AGG\AppData\Local\Temp\2\ (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,902] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,903] INFO Client environment:os.name=Windows Server 2012 R2 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,903] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,904] INFO Client environment:os.version=6.3 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,906] INFO Client environment:user.name=saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,907] INFO Client environment:user.home=C:\Users\saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,907] INFO Client environment:user.dir=D:\kafka_2.12-2.3.0\bin\windows (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,909] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@648c94da (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:38:36,932] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:38:36,934] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:38:36,938] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:38:36,938] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:64185 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-14 09:38:36,947] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:64185 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:36,950] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-08-14 09:38:36,963] INFO Established session 0x100154075a50000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:64185 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:38:36,965] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100154075a50000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:38:36,970] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:38:37,030] INFO Got user-level KeeperException when processing sessionid:0x100154075a50000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:38:37,044] INFO Got user-level KeeperException when processing sessionid:0x100154075a50000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:38:37,057] INFO Got user-level KeeperException when processing sessionid:0x100154075a50000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:38:37,253] INFO Got user-level KeeperException when processing sessionid:0x100154075a50000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:38:37,261] INFO Cluster ID = dpKdDN1LRtm_XfK_Gv1SdA (kafka.server.KafkaServer)
[2019-08-14 09:38:37,266] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-08-14 09:38:37,325] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 09:38:37,376] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 09:38:37,446] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:38:37,447] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:38:37,448] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:38:37,474] INFO Log directory D:\tmp\kafka-logs not found, creating it. (kafka.log.LogManager)
[2019-08-14 09:38:37,482] INFO Loading logs. (kafka.log.LogManager)
[2019-08-14 09:38:37,491] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2019-08-14 09:38:37,507] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-14 09:38:37,511] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-14 09:38:37,928] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-14 09:38:37,962] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-08-14 09:38:37,964] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-08-14 09:38:37,989] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:38:37,990] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:38:37,991] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:38:37,991] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:38:38,005] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-14 09:38:38,030] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-14 09:38:38,055] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1565800718047,1565800718047,1,0,0,72080960633765888,244,0,24
 (kafka.zk.KafkaZkClient)
[2019-08-14 09:38:38,057] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(SAKSHAMA2012.pacific.costcotravel.com,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2019-08-14 09:38:38,059] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-08-14 09:38:38,120] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:38:38,123] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:38:38,124] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:38:38,134] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-08-14 09:38:38,143] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:38:38,145] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:38:38,154] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 09:38:38,162] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-14 09:38:38,194] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-14 09:38:38,196] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-14 09:38:38,200] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-14 09:38:38,264] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-14 09:38:38,275] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-14 09:38:38,282] INFO Got user-level KeeperException when processing sessionid:0x100154075a50000 type:multi cxid:0x38 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:38:38,295] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-14 09:38:38,298] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-14 09:38:38,308] INFO Kafka startTimeMs: 1565800718276 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-14 09:38:38,315] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-08-14 09:41:15,556] INFO Creating topic cwct-allEvents-1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-08-14 09:41:15,559] INFO Got user-level KeeperException when processing sessionid:0x100154075a50000 type:setData cxid:0x3e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics/cwct-allEvents-1 Error:KeeperErrorCode = NoNode for /config/topics/cwct-allEvents-1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:41:15,620] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(cwct-allEvents-1-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:41:15,679] INFO [Log partition=cwct-allEvents-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-14 09:41:15,687] INFO [Log partition=cwct-allEvents-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-08-14 09:41:15,689] INFO Created log for partition cwct-allEvents-1-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-08-14 09:41:15,695] INFO [Partition cwct-allEvents-1-0 broker=0] No checkpointed highwatermark is found for partition cwct-allEvents-1-0 (kafka.cluster.Partition)
[2019-08-14 09:41:15,698] INFO Replica loaded for partition cwct-allEvents-1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:41:15,701] INFO [Partition cwct-allEvents-1-0 broker=0] cwct-allEvents-1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:42:15,972] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-08-14 09:42:15,973] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-08-14 09:42:15,991] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-08-14 09:42:15,994] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-14 09:42:15,996] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-14 09:42:15,996] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-14 09:42:15,997] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-08-14 09:42:16,008] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-08-14 09:42:16,009] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-08-14 09:42:16,012] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-08-14 09:42:16,019] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-08-14 09:42:16,021] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,109] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,109] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,112] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-14 09:42:16,113] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-14 09:42:16,114] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-08-14 09:42:16,115] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-14 09:42:16,116] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-14 09:42:16,116] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-14 09:42:16,117] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-14 09:42:16,118] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:42:16,119] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,260] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,260] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,261] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,456] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,456] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,457] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:42:16,459] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-08-14 09:42:16,460] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-14 09:42:16,461] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-14 09:42:16,461] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-14 09:42:16,463] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:42:16,465] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:42:16,466] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-14 09:42:16,466] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-14 09:42:16,467] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,522] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,522] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,523] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,529] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,529] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,530] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,729] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,729] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,729] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,915] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,915] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:16,920] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-08-14 09:42:16,921] INFO Shutting down. (kafka.log.LogManager)
[2019-08-14 09:42:16,946] INFO Shutdown complete. (kafka.log.LogManager)
[2019-08-14 09:42:16,955] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:42:16,957] INFO Processed session termination for sessionid: 0x100154075a50000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:16,960] INFO Session: 0x100154075a50000 closed (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:16,961] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:64185 which had sessionid 0x100154075a50000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-14 09:42:16,960] INFO EventThread shut down for session: 0x100154075a50000 (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:42:16,962] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:42:16,963] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:42:17,558] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:42:17,558] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:42:17,559] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:42:18,559] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:42:18,559] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:42:18,560] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:42:19,559] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:42:19,559] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:42:19,561] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-08-14 09:42:19,585] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-08-14 09:42:19,588] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-08-14 09:42:53,063] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-08-14 09:42:53,066] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 09:42:53,066] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 09:42:53,067] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 09:42:53,067] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-08-14 09:42:53,084] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-08-14 09:42:53,084] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-08-14 09:42:53,095] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,095] INFO Server environment:host.name=SAKSHAMA2012.pacific.costcotravel.com (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,096] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,096] INFO Server environment:java.vendor=AdoptOpenJDK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,097] INFO Server environment:java.home=D:\java\jdk (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,098] INFO Server environment:java.class.path=..;D:\kafka_2.12-2.3.0\libs\activation-1.1.1.jar;D:\kafka_2.12-2.3.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\argparse4j-0.7.0.jar;D:\kafka_2.12-2.3.0\libs\audience-annotations-0.5.0.jar;D:\kafka_2.12-2.3.0\libs\commons-lang3-3.8.1.jar;D:\kafka_2.12-2.3.0\libs\connect-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-basic-auth-extension-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-file-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-json-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-runtime-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-transforms-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\guava-20.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-api-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-locator-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-utils-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jackson-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-core-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-databind-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-dataformat-csv-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-datatype-jdk8-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-base-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-json-provider-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-jaxb-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-paranamer-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-scala_2.12-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka_2.12-2.3.0\libs\jakarta.inject-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka_2.12-2.3.0\libs\javassist-3.22.0-CR2.jar;D:\kafka_2.12-2.3.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka_2.12-2.3.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka_2.12-2.3.0\libs\jaxb-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\jersey-client-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-common-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-hk2-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-server-2.28.jar;D:\kafka_2.12-2.3.0\libs\jetty-client-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-continuation-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-http-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-io-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-security-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-server-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlet-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlets-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-util-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jopt-simple-5.0.4.jar;D:\kafka_2.12-2.3.0\libs\jsr305-3.0.2.jar;D:\kafka_2.12-2.3.0\libs\kafka-clients-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-log4j-appender-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-examples-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-scala_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-test-utils-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-tools-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar.asc;D:\kafka_2.12-2.3.0\libs\log4j-1.2.17.jar;D:\kafka_2.12-2.3.0\libs\lz4-java-1.6.0.jar;D:\kafka_2.12-2.3.0\libs\maven-artifact-3.6.1.jar;D:\kafka_2.12-2.3.0\libs\metrics-core-2.2.0.jar;D:\kafka_2.12-2.3.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka_2.12-2.3.0\libs\paranamer-2.8.jar;D:\kafka_2.12-2.3.0\libs\plexus-utils-3.2.0.jar;D:\kafka_2.12-2.3.0\libs\reflections-0.9.11.jar;D:\kafka_2.12-2.3.0\libs\rocksdbjni-5.18.3.jar;D:\kafka_2.12-2.3.0\libs\scala-library-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\scala-logging_2.12-3.9.0.jar;D:\kafka_2.12-2.3.0\libs\scala-reflect-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\slf4j-api-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\slf4j-log4j12-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\snappy-java-1.1.7.3.jar;D:\kafka_2.12-2.3.0\libs\spotbugs-annotations-3.1.9.jar;D:\kafka_2.12-2.3.0\libs\validation-api-2.0.1.Final.jar;D:\kafka_2.12-2.3.0\libs\zkclient-0.11.jar;D:\kafka_2.12-2.3.0\libs\zookeeper-3.4.14.jar;D:\kafka_2.12-2.3.0\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,115] INFO Server environment:java.library.path=D:\java\jdk\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\Java\jdk1.8.0_73\bin;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;D:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\ManagementStudio\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;D:\confluent-5.2.2\bin;D:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\saksham.aggarwal\AppData\Local\atom\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,119] INFO Server environment:java.io.tmpdir=C:\Users\SAKSHA~1.AGG\AppData\Local\Temp\2\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,120] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,120] INFO Server environment:os.name=Windows Server 2012 R2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,121] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,122] INFO Server environment:os.version=6.3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,123] INFO Server environment:user.name=saksham.aggarwal (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,124] INFO Server environment:user.home=C:\Users\saksham.aggarwal (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,125] INFO Server environment:user.dir=D:\kafka_2.12-2.3.0\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,135] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,136] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,142] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:53,161] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-08-14 09:42:53,164] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-14 09:42:56,868] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-14 09:42:57,448] INFO starting (kafka.server.KafkaServer)
[2019-08-14 09:42:57,449] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-14 09:42:57,486] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:42:57,494] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,494] INFO Client environment:host.name=SAKSHAMA2012.pacific.costcotravel.com (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,494] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,494] INFO Client environment:java.vendor=AdoptOpenJDK (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,495] INFO Client environment:java.home=D:\java\jdk (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,495] INFO Client environment:java.class.path=..;D:\kafka_2.12-2.3.0\libs\activation-1.1.1.jar;D:\kafka_2.12-2.3.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\argparse4j-0.7.0.jar;D:\kafka_2.12-2.3.0\libs\audience-annotations-0.5.0.jar;D:\kafka_2.12-2.3.0\libs\commons-lang3-3.8.1.jar;D:\kafka_2.12-2.3.0\libs\connect-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-basic-auth-extension-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-file-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-json-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-runtime-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-transforms-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\guava-20.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-api-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-locator-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-utils-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jackson-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-core-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-databind-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-dataformat-csv-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-datatype-jdk8-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-base-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-json-provider-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-jaxb-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-paranamer-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-scala_2.12-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka_2.12-2.3.0\libs\jakarta.inject-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka_2.12-2.3.0\libs\javassist-3.22.0-CR2.jar;D:\kafka_2.12-2.3.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka_2.12-2.3.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka_2.12-2.3.0\libs\jaxb-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\jersey-client-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-common-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-hk2-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-server-2.28.jar;D:\kafka_2.12-2.3.0\libs\jetty-client-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-continuation-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-http-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-io-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-security-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-server-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlet-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlets-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-util-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jopt-simple-5.0.4.jar;D:\kafka_2.12-2.3.0\libs\jsr305-3.0.2.jar;D:\kafka_2.12-2.3.0\libs\kafka-clients-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-log4j-appender-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-examples-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-scala_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-test-utils-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-tools-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar.asc;D:\kafka_2.12-2.3.0\libs\log4j-1.2.17.jar;D:\kafka_2.12-2.3.0\libs\lz4-java-1.6.0.jar;D:\kafka_2.12-2.3.0\libs\maven-artifact-3.6.1.jar;D:\kafka_2.12-2.3.0\libs\metrics-core-2.2.0.jar;D:\kafka_2.12-2.3.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka_2.12-2.3.0\libs\paranamer-2.8.jar;D:\kafka_2.12-2.3.0\libs\plexus-utils-3.2.0.jar;D:\kafka_2.12-2.3.0\libs\reflections-0.9.11.jar;D:\kafka_2.12-2.3.0\libs\rocksdbjni-5.18.3.jar;D:\kafka_2.12-2.3.0\libs\scala-library-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\scala-logging_2.12-3.9.0.jar;D:\kafka_2.12-2.3.0\libs\scala-reflect-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\slf4j-api-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\slf4j-log4j12-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\snappy-java-1.1.7.3.jar;D:\kafka_2.12-2.3.0\libs\spotbugs-annotations-3.1.9.jar;D:\kafka_2.12-2.3.0\libs\validation-api-2.0.1.Final.jar;D:\kafka_2.12-2.3.0\libs\zkclient-0.11.jar;D:\kafka_2.12-2.3.0\libs\zookeeper-3.4.14.jar;D:\kafka_2.12-2.3.0\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,509] INFO Client environment:java.library.path=D:\java\jdk\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\Java\jdk1.8.0_73\bin;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;D:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\ManagementStudio\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;D:\confluent-5.2.2\bin;D:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\saksham.aggarwal\AppData\Local\atom\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,514] INFO Client environment:java.io.tmpdir=C:\Users\SAKSHA~1.AGG\AppData\Local\Temp\2\ (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,515] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,515] INFO Client environment:os.name=Windows Server 2012 R2 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,516] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,517] INFO Client environment:os.version=6.3 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,518] INFO Client environment:user.name=saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,519] INFO Client environment:user.home=C:\Users\saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,520] INFO Client environment:user.dir=D:\kafka_2.12-2.3.0\bin\windows (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,522] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@648c94da (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:42:57,547] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:42:57,550] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:42:57,554] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:42:57,554] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:64279 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-14 09:42:57,563] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:64279 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:57,566] INFO Creating new log file: log.24 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-08-14 09:42:57,573] INFO Established session 0x10015447e5a0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:64279 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:42:57,575] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10015447e5a0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:42:57,579] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:42:57,626] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:create cxid:0x1 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:57,648] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:create cxid:0x2 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:57,653] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:create cxid:0x3 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:57,657] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:create cxid:0x4 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:57,665] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:create cxid:0x5 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:57,668] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:create cxid:0x6 zxid:0x2a txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:57,672] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:create cxid:0x7 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:57,675] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:create cxid:0x8 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:57,679] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:create cxid:0x9 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:57,683] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:create cxid:0xa zxid:0x2e txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:57,686] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:create cxid:0xb zxid:0x2f txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:57,691] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:create cxid:0xc zxid:0x30 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:57,694] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:create cxid:0xd zxid:0x31 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:57,856] INFO Cluster ID = dpKdDN1LRtm_XfK_Gv1SdA (kafka.server.KafkaServer)
[2019-08-14 09:42:57,933] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 09:42:57,986] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 09:42:58,050] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:42:58,052] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:42:58,050] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:42:58,090] INFO Loading logs. (kafka.log.LogManager)
[2019-08-14 09:42:58,181] INFO [Log partition=cwct-allEvents-1-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-08-14 09:42:58,193] INFO [ProducerStateManager partition=cwct-allEvents-1-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-08-14 09:42:58,203] INFO [Log partition=cwct-allEvents-1-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 83 ms (kafka.log.Log)
[2019-08-14 09:42:58,217] INFO Logs loading complete in 126 ms. (kafka.log.LogManager)
[2019-08-14 09:42:58,230] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-14 09:42:58,232] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-14 09:42:58,640] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-14 09:42:58,680] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-08-14 09:42:58,683] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-08-14 09:42:58,713] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:58,713] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:58,714] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:58,715] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:58,728] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-14 09:42:58,789] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-14 09:42:58,811] INFO Stat of the created znode at /brokers/ids/0 is: 50,50,1565800978804,1565800978804,1,0,0,72080977959714816,244,0,50
 (kafka.zk.KafkaZkClient)
[2019-08-14 09:42:58,813] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(SAKSHAMA2012.pacific.costcotravel.com,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 50 (kafka.zk.KafkaZkClient)
[2019-08-14 09:42:58,889] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:58,894] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:58,894] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:42:58,916] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:42:58,918] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:42:58,924] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 09:42:58,937] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-14 09:42:58,967] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-14 09:42:58,970] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-14 09:42:58,970] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-14 09:42:59,022] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-14 09:42:59,041] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-14 09:42:59,053] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-14 09:42:59,054] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-14 09:42:59,055] INFO Kafka startTimeMs: 1565800979044 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-14 09:42:59,058] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-08-14 09:42:59,067] INFO Got user-level KeeperException when processing sessionid:0x10015447e5a0000 type:multi cxid:0x32 zxid:0x35 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:42:59,104] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(cwct-allEvents-1-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:42:59,115] INFO Replica loaded for partition cwct-allEvents-1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-14 09:42:59,123] INFO [Partition cwct-allEvents-1-0 broker=0] cwct-allEvents-1-0 starts at Leader Epoch 0 from offset 10. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-14 09:43:28,238] INFO [Log partition=cwct-allEvents-1-0, dir=D:\tmp\kafka-logs] Found deletable segments with base offsets [0] due to retention time 604800000ms breach (kafka.log.Log)
[2019-08-14 09:43:28,254] INFO [Log partition=cwct-allEvents-1-0, dir=D:\tmp\kafka-logs] Rolled new log segment at offset 10 in 4 ms. (kafka.log.Log)
[2019-08-14 09:43:28,256] INFO [Log partition=cwct-allEvents-1-0, dir=D:\tmp\kafka-logs] Scheduling log segment [baseOffset 0, size 6191] for deletion. (kafka.log.Log)
[2019-08-14 09:43:28,259] ERROR Error while deleting segments for cwct-allEvents-1-0 in dir D:\tmp\kafka-logs (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\cwct-allEvents-1-0\00000000000000000000.index -> D:\tmp\kafka-logs\cwct-allEvents-1-0\00000000000000000000.index.deleted: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:509)
	at kafka.log.Log.asyncDeleteSegment(Log.scala:1962)
	at kafka.log.Log.deleteSegment(Log.scala:1947)
	at kafka.log.Log.$anonfun$deleteSegments$3(Log.scala:1493)
	at kafka.log.Log.$anonfun$deleteSegments$3$adapted(Log.scala:1493)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.log.Log.$anonfun$deleteSegments$2(Log.scala:1493)
	at scala.runtime.java8.JFunction0$mcI$sp.apply(JFunction0$mcI$sp.java:23)
	at kafka.log.Log.maybeHandleIOException(Log.scala:2065)
	at kafka.log.Log.deleteSegments(Log.scala:1484)
	at kafka.log.Log.deleteOldSegments(Log.scala:1479)
	at kafka.log.Log.deleteRetentionMsBreachedSegments(Log.scala:1557)
	at kafka.log.Log.deleteOldSegments(Log.scala:1547)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3(LogManager.scala:914)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3$adapted(LogManager.scala:911)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:911)
	at kafka.log.LogManager.$anonfun$startup$2(LogManager.scala:395)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:65)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\cwct-allEvents-1-0\00000000000000000000.index -> D:\tmp\kafka-logs\cwct-allEvents-1-0\00000000000000000000.index.deleted: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 29 more
[2019-08-14 09:43:28,277] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-08-14 09:43:28,278] ERROR Uncaught exception in scheduled task 'kafka-log-retention' (kafka.utils.KafkaScheduler)
org.apache.kafka.common.errors.KafkaStorageException: Error while deleting segments for cwct-allEvents-1-0 in dir D:\tmp\kafka-logs
Caused by: java.nio.file.FileSystemException: D:\tmp\kafka-logs\cwct-allEvents-1-0\00000000000000000000.index -> D:\tmp\kafka-logs\cwct-allEvents-1-0\00000000000000000000.index.deleted: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:509)
	at kafka.log.Log.asyncDeleteSegment(Log.scala:1962)
	at kafka.log.Log.deleteSegment(Log.scala:1947)
	at kafka.log.Log.$anonfun$deleteSegments$3(Log.scala:1493)
	at kafka.log.Log.$anonfun$deleteSegments$3$adapted(Log.scala:1493)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.log.Log.$anonfun$deleteSegments$2(Log.scala:1493)
	at scala.runtime.java8.JFunction0$mcI$sp.apply(JFunction0$mcI$sp.java:23)
	at kafka.log.Log.maybeHandleIOException(Log.scala:2065)
	at kafka.log.Log.deleteSegments(Log.scala:1484)
	at kafka.log.Log.deleteOldSegments(Log.scala:1479)
	at kafka.log.Log.deleteRetentionMsBreachedSegments(Log.scala:1557)
	at kafka.log.Log.deleteOldSegments(Log.scala:1547)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3(LogManager.scala:914)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3$adapted(LogManager.scala:911)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:911)
	at kafka.log.LogManager.$anonfun$startup$2(LogManager.scala:395)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:65)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\cwct-allEvents-1-0\00000000000000000000.index -> D:\tmp\kafka-logs\cwct-allEvents-1-0\00000000000000000000.index.deleted: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 29 more
[2019-08-14 09:43:28,279] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(cwct-allEvents-1-0) (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:43:28,296] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(cwct-allEvents-1-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-14 09:43:28,302] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions cwct-allEvents-1-0 and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-08-14 09:43:28,303] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-08-14 09:43:28,306] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-08-14 09:43:28,641] WARN Exception causing close of session 0x10015447e5a0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-14 09:43:28,643] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:64279 which had sessionid 0x10015447e5a0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-14 09:43:35,870] INFO Expiring session 0x10015447e5a0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:43:35,871] INFO Processed session termination for sessionid: 0x10015447e5a0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:44:00,175] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-08-14 09:44:00,179] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 09:44:00,180] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 09:44:00,181] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-14 09:44:00,182] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-08-14 09:44:00,198] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-08-14 09:44:00,199] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-08-14 09:44:00,210] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,210] INFO Server environment:host.name=SAKSHAMA2012.pacific.costcotravel.com (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,211] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,212] INFO Server environment:java.vendor=AdoptOpenJDK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,213] INFO Server environment:java.home=D:\java\jdk (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,214] INFO Server environment:java.class.path=..;D:\kafka_2.12-2.3.0\libs\activation-1.1.1.jar;D:\kafka_2.12-2.3.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\argparse4j-0.7.0.jar;D:\kafka_2.12-2.3.0\libs\audience-annotations-0.5.0.jar;D:\kafka_2.12-2.3.0\libs\commons-lang3-3.8.1.jar;D:\kafka_2.12-2.3.0\libs\connect-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-basic-auth-extension-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-file-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-json-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-runtime-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-transforms-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\guava-20.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-api-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-locator-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-utils-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jackson-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-core-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-databind-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-dataformat-csv-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-datatype-jdk8-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-base-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-json-provider-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-jaxb-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-paranamer-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-scala_2.12-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka_2.12-2.3.0\libs\jakarta.inject-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka_2.12-2.3.0\libs\javassist-3.22.0-CR2.jar;D:\kafka_2.12-2.3.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka_2.12-2.3.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka_2.12-2.3.0\libs\jaxb-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\jersey-client-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-common-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-hk2-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-server-2.28.jar;D:\kafka_2.12-2.3.0\libs\jetty-client-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-continuation-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-http-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-io-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-security-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-server-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlet-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlets-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-util-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jopt-simple-5.0.4.jar;D:\kafka_2.12-2.3.0\libs\jsr305-3.0.2.jar;D:\kafka_2.12-2.3.0\libs\kafka-clients-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-log4j-appender-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-examples-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-scala_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-test-utils-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-tools-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar.asc;D:\kafka_2.12-2.3.0\libs\log4j-1.2.17.jar;D:\kafka_2.12-2.3.0\libs\lz4-java-1.6.0.jar;D:\kafka_2.12-2.3.0\libs\maven-artifact-3.6.1.jar;D:\kafka_2.12-2.3.0\libs\metrics-core-2.2.0.jar;D:\kafka_2.12-2.3.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka_2.12-2.3.0\libs\paranamer-2.8.jar;D:\kafka_2.12-2.3.0\libs\plexus-utils-3.2.0.jar;D:\kafka_2.12-2.3.0\libs\reflections-0.9.11.jar;D:\kafka_2.12-2.3.0\libs\rocksdbjni-5.18.3.jar;D:\kafka_2.12-2.3.0\libs\scala-library-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\scala-logging_2.12-3.9.0.jar;D:\kafka_2.12-2.3.0\libs\scala-reflect-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\slf4j-api-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\slf4j-log4j12-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\snappy-java-1.1.7.3.jar;D:\kafka_2.12-2.3.0\libs\spotbugs-annotations-3.1.9.jar;D:\kafka_2.12-2.3.0\libs\validation-api-2.0.1.Final.jar;D:\kafka_2.12-2.3.0\libs\zkclient-0.11.jar;D:\kafka_2.12-2.3.0\libs\zookeeper-3.4.14.jar;D:\kafka_2.12-2.3.0\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,230] INFO Server environment:java.library.path=D:\java\jdk\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\Java\jdk1.8.0_73\bin;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;D:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\ManagementStudio\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;D:\confluent-5.2.2\bin;D:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\saksham.aggarwal\AppData\Local\atom\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,233] INFO Server environment:java.io.tmpdir=C:\Users\SAKSHA~1.AGG\AppData\Local\Temp\2\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,234] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,235] INFO Server environment:os.name=Windows Server 2012 R2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,235] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,236] INFO Server environment:os.version=6.3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,236] INFO Server environment:user.name=saksham.aggarwal (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,237] INFO Server environment:user.home=C:\Users\saksham.aggarwal (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,238] INFO Server environment:user.dir=D:\kafka_2.12-2.3.0\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,247] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,248] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,254] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:00,272] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-08-14 09:44:00,275] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-14 09:44:06,131] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-14 09:44:06,677] INFO starting (kafka.server.KafkaServer)
[2019-08-14 09:44:06,678] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-14 09:44:06,715] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:44:06,722] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,723] INFO Client environment:host.name=SAKSHAMA2012.pacific.costcotravel.com (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,723] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,724] INFO Client environment:java.vendor=AdoptOpenJDK (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,725] INFO Client environment:java.home=D:\java\jdk (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,725] INFO Client environment:java.class.path=..;D:\kafka_2.12-2.3.0\libs\activation-1.1.1.jar;D:\kafka_2.12-2.3.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\argparse4j-0.7.0.jar;D:\kafka_2.12-2.3.0\libs\audience-annotations-0.5.0.jar;D:\kafka_2.12-2.3.0\libs\commons-lang3-3.8.1.jar;D:\kafka_2.12-2.3.0\libs\connect-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-basic-auth-extension-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-file-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-json-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-runtime-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\connect-transforms-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\guava-20.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-api-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-locator-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\hk2-utils-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jackson-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-core-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-databind-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-dataformat-csv-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-datatype-jdk8-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-base-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-jaxrs-json-provider-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-jaxb-annotations-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-paranamer-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jackson-module-scala_2.12-2.9.9.jar;D:\kafka_2.12-2.3.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka_2.12-2.3.0\libs\jakarta.inject-2.5.0.jar;D:\kafka_2.12-2.3.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka_2.12-2.3.0\libs\javassist-3.22.0-CR2.jar;D:\kafka_2.12-2.3.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka_2.12-2.3.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka_2.12-2.3.0\libs\jaxb-api-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\jersey-client-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-common-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-hk2-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka_2.12-2.3.0\libs\jersey-server-2.28.jar;D:\kafka_2.12-2.3.0\libs\jetty-client-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-continuation-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-http-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-io-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-security-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-server-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlet-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-servlets-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jetty-util-9.4.18.v20190429.jar;D:\kafka_2.12-2.3.0\libs\jopt-simple-5.0.4.jar;D:\kafka_2.12-2.3.0\libs\jsr305-3.0.2.jar;D:\kafka_2.12-2.3.0\libs\kafka-clients-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-log4j-appender-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-examples-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-scala_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-streams-test-utils-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka-tools-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-javadoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-scaladoc.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test-sources.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0-test.jar.asc;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar;D:\kafka_2.12-2.3.0\libs\kafka_2.12-2.3.0.jar.asc;D:\kafka_2.12-2.3.0\libs\log4j-1.2.17.jar;D:\kafka_2.12-2.3.0\libs\lz4-java-1.6.0.jar;D:\kafka_2.12-2.3.0\libs\maven-artifact-3.6.1.jar;D:\kafka_2.12-2.3.0\libs\metrics-core-2.2.0.jar;D:\kafka_2.12-2.3.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka_2.12-2.3.0\libs\paranamer-2.8.jar;D:\kafka_2.12-2.3.0\libs\plexus-utils-3.2.0.jar;D:\kafka_2.12-2.3.0\libs\reflections-0.9.11.jar;D:\kafka_2.12-2.3.0\libs\rocksdbjni-5.18.3.jar;D:\kafka_2.12-2.3.0\libs\scala-library-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\scala-logging_2.12-3.9.0.jar;D:\kafka_2.12-2.3.0\libs\scala-reflect-2.12.8.jar;D:\kafka_2.12-2.3.0\libs\slf4j-api-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\slf4j-log4j12-1.7.26.jar;D:\kafka_2.12-2.3.0\libs\snappy-java-1.1.7.3.jar;D:\kafka_2.12-2.3.0\libs\spotbugs-annotations-3.1.9.jar;D:\kafka_2.12-2.3.0\libs\validation-api-2.0.1.Final.jar;D:\kafka_2.12-2.3.0\libs\zkclient-0.11.jar;D:\kafka_2.12-2.3.0\libs\zookeeper-3.4.14.jar;D:\kafka_2.12-2.3.0\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,739] INFO Client environment:java.library.path=D:\java\jdk\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\Java\jdk1.8.0_73\bin;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;D:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\ManagementStudio\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;D:\confluent-5.2.2\bin;D:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\saksham.aggarwal\AppData\Local\atom\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,743] INFO Client environment:java.io.tmpdir=C:\Users\SAKSHA~1.AGG\AppData\Local\Temp\2\ (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,744] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,744] INFO Client environment:os.name=Windows Server 2012 R2 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,745] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,745] INFO Client environment:os.version=6.3 (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,746] INFO Client environment:user.name=saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,747] INFO Client environment:user.home=C:\Users\saksham.aggarwal (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,747] INFO Client environment:user.dir=D:\kafka_2.12-2.3.0\bin\windows (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,749] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@648c94da (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:44:06,772] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:44:06,774] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:44:06,778] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:44:06,778] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:64319 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-14 09:44:06,786] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:64319 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:06,790] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-08-14 09:44:06,804] INFO Established session 0x1001545846d0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:64319 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-14 09:44:06,806] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1001545846d0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:44:06,810] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:44:06,877] INFO Got user-level KeeperException when processing sessionid:0x1001545846d0000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:44:06,893] INFO Got user-level KeeperException when processing sessionid:0x1001545846d0000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:44:06,906] INFO Got user-level KeeperException when processing sessionid:0x1001545846d0000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:44:07,118] INFO Got user-level KeeperException when processing sessionid:0x1001545846d0000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:44:07,126] INFO Cluster ID = hJuNdJzCTu6PEiTpqwfGgA (kafka.server.KafkaServer)
[2019-08-14 09:44:07,131] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-08-14 09:44:07,187] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 09:44:07,230] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-14 09:44:07,296] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:44:07,296] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:44:07,298] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:44:07,330] INFO Log directory D:\tmp\kafka-logs not found, creating it. (kafka.log.LogManager)
[2019-08-14 09:44:07,339] INFO Loading logs. (kafka.log.LogManager)
[2019-08-14 09:44:07,348] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2019-08-14 09:44:07,366] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-14 09:44:07,369] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-14 09:44:07,797] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-14 09:44:07,832] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-08-14 09:44:07,834] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-08-14 09:44:07,864] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:44:07,864] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:44:07,864] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:44:07,865] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:44:07,884] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-14 09:44:07,907] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-14 09:44:07,930] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1565801047921,1565801047921,1,0,0,72080982356590592,244,0,24
 (kafka.zk.KafkaZkClient)
[2019-08-14 09:44:07,931] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(SAKSHAMA2012.pacific.costcotravel.com,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2019-08-14 09:44:07,933] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-08-14 09:44:07,994] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:44:07,998] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:44:08,002] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:44:08,019] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-08-14 09:44:08,020] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:44:08,022] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:44:08,035] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-14 09:44:08,045] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-14 09:44:08,084] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-14 09:44:08,090] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-14 09:44:08,096] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-14 09:44:08,142] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-14 09:44:08,157] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-14 09:44:08,168] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-14 09:44:08,168] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-14 09:44:08,169] INFO Kafka startTimeMs: 1565801048158 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-14 09:44:08,175] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-08-14 09:44:08,177] INFO Got user-level KeeperException when processing sessionid:0x1001545846d0000 type:multi cxid:0x38 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:50:26,993] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-08-14 09:50:26,997] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-08-14 09:50:27,020] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-08-14 09:50:27,025] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-14 09:50:27,026] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-14 09:50:27,026] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-14 09:50:27,028] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-08-14 09:50:27,045] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-08-14 09:50:27,046] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-08-14 09:50:27,049] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-08-14 09:50:27,053] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-08-14 09:50:27,055] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,119] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,119] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,122] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-14 09:50:27,123] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-14 09:50:27,124] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-08-14 09:50:27,125] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-14 09:50:27,126] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-14 09:50:27,126] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-14 09:50:27,128] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-14 09:50:27,129] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:50:27,130] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,321] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,321] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,322] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,334] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,334] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,336] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-14 09:50:27,337] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-08-14 09:50:27,338] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-14 09:50:27,339] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-14 09:50:27,340] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-14 09:50:27,341] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:50:27,343] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-08-14 09:50:27,344] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-14 09:50:27,346] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-14 09:50:27,347] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,524] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,524] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,525] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,721] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,721] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,722] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,736] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,736] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,737] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,923] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,923] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-14 09:50:27,929] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-08-14 09:50:27,930] INFO Shutting down. (kafka.log.LogManager)
[2019-08-14 09:50:27,961] INFO Shutdown complete. (kafka.log.LogManager)
[2019-08-14 09:50:27,970] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:50:27,972] INFO Processed session termination for sessionid: 0x1001545846d0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-14 09:50:27,976] INFO Session: 0x1001545846d0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-08-14 09:50:27,975] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:64319 which had sessionid 0x1001545846d0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-14 09:50:27,977] INFO EventThread shut down for session: 0x1001545846d0000 (org.apache.zookeeper.ClientCnxn)
[2019-08-14 09:50:27,978] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-08-14 09:50:27,980] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:50:28,520] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:50:28,520] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:50:28,520] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:50:28,525] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:50:28,525] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:50:28,526] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:50:29,514] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:50:29,514] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-14 09:50:29,516] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-08-14 09:50:29,538] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-08-14 09:50:29,541] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
